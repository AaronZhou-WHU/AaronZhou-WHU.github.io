<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BinYingの部屋</title>
  
  <subtitle>知之为知之，不知为不知</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://aaronzhou-whu.github.io/"/>
  <updated>2019-09-20T06:00:15.000Z</updated>
  <id>https://aaronzhou-whu.github.io/</id>
  
  <author>
    <name>Aaron Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>SpringBoot中application和bootstrap配置文件的区别</title>
    <link href="https://aaronzhou-whu.github.io/SpringBoot%E4%B8%ADapplication%E5%92%8Cbootstrap%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://aaronzhou-whu.github.io/SpringBoot中application和bootstrap配置文件的区别/</id>
    <published>2019-09-20T05:44:59.000Z</published>
    <updated>2019-09-20T06:00:15.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="加载顺序"><a href="#加载顺序" class="headerlink" title="加载顺序"></a>加载顺序</h3><ul><li>bootstrap.yml（bootstrap.properties）先加载</li><li>application.yml（application.properties）后加载</li></ul><h3 id="二者不同"><a href="#二者不同" class="headerlink" title="二者不同"></a>二者不同</h3><p>跟 application 相比，bootstrap 配置文件具有以下几个特性：</p><ul><li>bootstrap 由父 ApplicationContext 加载，比 application 优先加载</li><li>bootstrap 里面的属性不能被覆盖<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3>application：主要用于spring boot 项目的自动化配置<br>bootstrap：</li><li>使用spring Cloud config 配置中心时，这时需要在bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息</li><li>一些固定的不能被覆盖的配置</li><li>一些加密/解密的场景</li></ul><p><strong>注意：一旦 bootStrap 被加载，则内容不会被覆盖，即便后期加载的 application 的内容标签与 bootstrap 的标签一致，application 也不会覆盖 bootstrap, 而 application 里面的内容可以动态替换。</strong> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;加载顺序&quot;&gt;&lt;a href=&quot;#加载顺序&quot; class=&quot;headerlink&quot; title=&quot;加载顺序&quot;&gt;&lt;/a&gt;加载顺序&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;bootstrap.yml（bootstrap.properties）先加载&lt;/li&gt;
&lt;li&gt;applicat
      
    
    </summary>
    
    
      <category term="SpringBoot" scheme="https://aaronzhou-whu.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>Java中值传递和引用传递以及mutable对象和immutable对象</title>
    <link href="https://aaronzhou-whu.github.io/Java%E4%B8%AD%E5%80%BC%E4%BC%A0%E9%80%92%E5%92%8C%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92%E4%BB%A5%E5%8F%8Amutable%E5%AF%B9%E8%B1%A1%E5%92%8Cimmutable%E5%AF%B9%E8%B1%A1/"/>
    <id>https://aaronzhou-whu.github.io/Java中值传递和引用传递以及mutable对象和immutable对象/</id>
    <published>2019-04-18T03:28:40.000Z</published>
    <updated>2019-04-18T05:10:24.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>基本数据类型传值，对形参的修改不会影响实参；</li><li>引用类型传引用，形参和实参指向同一个内存地址（同一个对象），所以对参数的修改会影响到实际的对象。</li><li>String, Integer, Double等immutable的类型特殊处理，可以理解为传值，最后的操作不会修改实参对象。</li></ol><p>第一个例子：基本类型<br>void foo(int value) {<br>    value = 100;<br>}<br>foo(num); // num 没有被改变</p><p>第二个例子：没有提供改变自身方法的引用类型<br>void foo(String text) {<br>    text = “windows”;<br>}<br>foo(str); // str 也没有被改变</p><p>第三个例子：提供了改变自身方法的引用类型<br>StringBuilder sb = new StringBuilder(“iphone”);<br>void foo(StringBuilder builder) {<br>    builder.append(“4”);<br>}<br>foo(sb); // sb 被改变了，变成了”iphone4”。</p><p>第四个例子：提供了改变自身方法的引用类型，但是不使用，而是使用赋值运算符。<br>StringBuilder sb = new StringBuilder(“iphone”);<br>void foo(StringBuilder builder) {<br>    builder = new StringBuilder(“ipad”);<br>}<br>foo(sb); // sb 没有被改变，还是 “iphone”。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;基本数据类型传值，对形参的修改不会影响实参；&lt;/li&gt;
&lt;li&gt;引用类型传引用，形参和实参指向同一个内存地址（同一个对象），所以对参数的修改会影响到实际的对象。&lt;/li&gt;
&lt;li&gt;String, Integer, Double等immutable的类型特殊处理，
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Springboot自定义数据源DataSource</title>
    <link href="https://aaronzhou-whu.github.io/Springboot%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E6%BA%90DataSource/"/>
    <id>https://aaronzhou-whu.github.io/Springboot自定义数据源DataSource/</id>
    <published>2019-04-10T11:59:38.000Z</published>
    <updated>2019-04-10T12:17:30.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Springboot使用JPA</strong><br>maven加入依赖：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><p>application.properties配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spring.jpa.database=oracle</span><br><span class="line">spring.datasource.driver-class-name=oracle.jdbc.driver.OracleDriver</span><br><span class="line">spring.datasource.url=jdbc:oracle:thin:@IP:port/sid</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=password</span><br></pre></td></tr></table></figure></p><p>经过以上简单配置，就可以使用jpa相关接口了，但是很多时候，密码并不是明文的，这时候就要用到自定义datasource来加载配置。</p><p><strong>自定义DataSource</strong><br>可以使用阿里的druid为自定义DataSource</p><p>maven加入依赖：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;druid&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.1.9&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><p>application.properties添加配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.datasource.type=com.alibaba.druid.pool.DruidDataSource</span><br></pre></td></tr></table></figure></p><p>自定义DataSourceAutoConfiguration类：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableConfigurationProperties</span>(DataSourceProperties.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataSourceAutoConfiguration</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    DataSourceProperties properties;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataSource <span class="title">dataSource</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">//可以在此处调用相关接口获取数据库的配置信息进行 DataSource 的配置</span></span><br><span class="line">        DruidDataSource dataSource = <span class="keyword">new</span> DruidDataSource();</span><br><span class="line">        dataSource.setUrl(properties.getUrl());</span><br><span class="line">        dataSource.setUsername(properties.getUsername());</span><br><span class="line">        <span class="comment">//密码处解密</span></span><br><span class="line">        <span class="comment">//dataSource.setPassword(properties.getPassword());</span></span><br><span class="line">        dataSource.setDriverClassName(properties.getDriverClassName());</span><br><span class="line">        <span class="keyword">return</span> dataSource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>配置好好，就可以跟之前的一样使用Jpa相关接口了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Springboot使用JPA&lt;/strong&gt;&lt;br&gt;maven加入依赖：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1
      
    
    </summary>
    
    
      <category term="Springboot JPA" scheme="https://aaronzhou-whu.github.io/tags/Springboot-JPA/"/>
    
  </entry>
  
  <entry>
    <title>docker安装es以及ik中文分词插件</title>
    <link href="https://aaronzhou-whu.github.io/docker%E5%AE%89%E8%A3%85es%E4%BB%A5%E5%8F%8Aik%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8F%92%E4%BB%B6/"/>
    <id>https://aaronzhou-whu.github.io/docker安装es以及ik中文分词插件/</id>
    <published>2019-04-09T11:08:57.000Z</published>
    <updated>2019-04-09T11:37:41.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Docker安装ElasticSearch</strong><br>安装：docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.2<br>启动：docker run -d –name es -p 9200:9200 -p 9300:9300 -e “discovery.type=single-node” docker.elastic.co/elasticsearch/elasticsearch:6.3.2</p><p><strong>Docker安装ElasticSearch-head</strong><br>安装：docker pull mobz/elasticsearch-head:5<br>启动：docker run -d -p 9100:9100 docker.io/mobz/elasticsearch-head:5</p><p>浏览器输入localhost:9100打开elasticsearch-head页面，填入ES地址localhost:9200,即可进入es界面。</p><p>跨域拒绝访问问题：<br>在elasticsearch.yml中添加：</p><blockquote><p>http.cors.enabled: true<br>http.cors.allow-origin: “*”</p></blockquote><p><strong>Docker安装ik中文分词插件</strong><br>进入es容器内，docker exec -it es /bin/bash</p><blockquote><p>elasticsearch-plugin install <a href="https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.2/elasticsearch-analysis-ik-6.3.2.zip" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.2/elasticsearch-analysis-ik-6.3.2.zip</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Docker安装ElasticSearch&lt;/strong&gt;&lt;br&gt;安装：docker pull docker.elastic.co/elasticsearch/elasticsearch:6.3.2&lt;br&gt;启动：docker run -d –name es
      
    
    </summary>
    
    
      <category term="ElasticSearch" scheme="https://aaronzhou-whu.github.io/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>MongoTemplate两种方式读取mongodb</title>
    <link href="https://aaronzhou-whu.github.io/MongoTemplate%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E8%AF%BB%E5%8F%96mongodb/"/>
    <id>https://aaronzhou-whu.github.io/MongoTemplate两种方式读取mongodb/</id>
    <published>2019-01-17T12:51:18.000Z</published>
    <updated>2019-01-17T12:51:55.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="映射方式读取"><a href="#映射方式读取" class="headerlink" title="映射方式读取"></a>映射方式读取</h3><p>一般Java开发都是基于面向对象的，所以大部分情况下都是采用的映射方式，即将mongodb的document映射成java entity，并在entity类上添加@Document(collection =”xxx_collection”)注解，以及在类的变量上添加@Field(“xxx_name”)注解。在使用MongoTemplate的查询mongodb的时候，先创建一个Query对象–查询条件，然后用mongoTemplate.find(query, entityClass)这样的方式，就可以返回对应的实体对象集合。方式如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Query query=<span class="keyword">new</span> Query(Criteria.where(<span class="string">"filed"</span>).is(<span class="string">"value"</span>));</span><br><span class="line">mongoTemplate.findOne(query, entity.class);</span><br></pre></td></tr></table></figure></p><h3 id="非映射方式读取"><a href="#非映射方式读取" class="headerlink" title="非映射方式读取"></a>非映射方式读取</h3><p>但有时候，mongodb里面的数据结构经常变动，此时就不能再使用MongoTemplate封装好的find方法（<strong>规范开发多么重要啊</strong>），可以使用原生的方式读取mongodb。方式如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.获取集合对象</span></span><br><span class="line">MongoCollection&lt;Document&gt; collection = mongoTemplate.getCollection(<span class="string">"xxx"</span>);</span><br><span class="line"><span class="comment">//2.创建用于查询的BSON对象</span></span><br><span class="line">Bson bson = eq(<span class="string">"field"</span>, <span class="string">"value"</span>);</span><br><span class="line"><span class="comment">//3.利用bson条件查询结果</span></span><br><span class="line">FindIterable&lt;Document&gt; documents = collection.find(bson);</span><br></pre></td></tr></table></figure></p><p><em><code>PS</code></em> : 在定义entity类的时候加上@Data注解可以省去Getter,Setter以及toString等的代码</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;映射方式读取&quot;&gt;&lt;a href=&quot;#映射方式读取&quot; class=&quot;headerlink&quot; title=&quot;映射方式读取&quot;&gt;&lt;/a&gt;映射方式读取&lt;/h3&gt;&lt;p&gt;一般Java开发都是基于面向对象的，所以大部分情况下都是采用的映射方式，即将mongodb的document
      
    
    </summary>
    
    
      <category term="MongoTemplate" scheme="https://aaronzhou-whu.github.io/tags/MongoTemplate/"/>
    
  </entry>
  
  <entry>
    <title>激活函数对比</title>
    <link href="https://aaronzhou-whu.github.io/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%94/"/>
    <id>https://aaronzhou-whu.github.io/激活函数对比/</id>
    <published>2019-01-08T11:39:53.000Z</published>
    <updated>2019-01-08T13:32:26.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p><strong>激活函数</strong>简单来说就是表示神经元中输入与输出之间的映射关系。</p><p>具有以下特征：（<em>摘抄至相关书籍</em>）</p><ul><li>非线性：当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。</li><li>可微：当优化方法是基于梯度的时候，这个性质是必须的。</li><li>单调性：当激活函数是单调的时候，单层网络能够保证是凸函数。</li><li>f(x)≈x：当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效。</li><li>输出值范围：当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的学习率。</li></ul><h3 id="激活函数有哪些"><a href="#激活函数有哪些" class="headerlink" title="激活函数有哪些"></a>激活函数有哪些</h3><p><strong>Sigmoid</strong> - 取值范围为(0,1)，适用于二分类<br><strong>Tanh</strong> - 取值范围为[-1,1]，适用于二分类<br><strong>Rectified Linear Unit(ReLU)</strong> - 输入信号 <0 时，输出都是0，="">0 的情况下，输出等于输入，用于隐层神经元输出<br><strong>Softmax</strong> - 取值范围为[0,1]，所有概率的和将等于1，用于多分类</0></p><p>Sigmoid特点：</p><ol><li>激活函数计算量大，反向传播求误差梯度时，求导涉及除法</li><li>反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练<br>Tanh特点：<br>Tanh是Sigmoid的变形，与 sigmoid 不同的是，tanh 是0均值的。因此实际应用中，tanh 会比 sigmoid 更好。<br>ReLU特点：</li><li>在输入为正数的时候，不存在梯度饱和问题。</li><li>计算速度要快很多。ReLU函数只有线性关系，不管是前向传播还是反向传播，都比sigmod和tanh要快很多。（sigmod和tanh要计算指数，计算速度会比较慢）</li></ol></li></ul><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>使用 ReLU，就要注意设置 learning rate，不要让网络训练过程中出现很多 “dead” 神经元</li><li>如果“dead”无法解决，可以尝试 Leaky ReLU、PReLU 、RReLU等Relu变体来替代ReLU</li><li>不建议使用 sigmoid，如果一定要使用，也可以用tanh来替代</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;h3 id=&quot;激活函数&quot;&gt;&lt;a href=&quot;#激活函数&quot; class=&quot;headerlink&quot; title=&quot;激活函数&quot;&gt;&lt;/a&gt;激活函数&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;激活函数&lt;/strong&gt;简单来说就是表示神经元中输入与输出之间的映射关系。&lt;/p&gt;
&lt;p
      
    
    </summary>
    
    
      <category term="DeepLearning" scheme="https://aaronzhou-whu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>Apollo和SpringCloudConfig</title>
    <link href="https://aaronzhou-whu.github.io/Apollo%E5%92%8CSpringCloudConfig/"/>
    <id>https://aaronzhou-whu.github.io/Apollo和SpringCloudConfig/</id>
    <published>2018-11-21T01:26:06.000Z</published>
    <updated>2018-11-21T01:38:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>集中管理的需求：一个使用微服务架构的应用系统可能会包括成百上千个微服务，因此集中管理很有必要</p><p>不同环境不同配置：例如数据源在不同的环境（dev，test）是不同的</p><p>运行期间可以动态调整。例如根据各个微服务的负载状况，动态调整数据源连接池大小或者熔断阀值，并且调整时不停止微服务</p><p>配置修改后可以自动更新</p><p>因此需要使用统一的配置服务来管理。<br>市面上有Spring Cloud生态圈中的Config，还有别的，如百度的disconf、阿里的diamond和协程的apollo，disconf已经停止维护了，用的比较多的还是config和apollo，二者的区别如下：<br><img src="../../images/apollo-config.png" alt="apollo-config.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;集中管理的需求：一个使用微服务架构的应用系统可能会包括成百上千个微服务，因此集中管理很有必要&lt;/p&gt;
&lt;p&gt;不同环境不同配置：例如数据源在不同的环境（dev，test）是不同的&lt;/p&gt;
&lt;p&gt;运行期间可以动态调整。例如根据各个微服务的负载状况，动态调整数据源连接池大小或者熔
      
    
    </summary>
    
    
      <category term="SpringCloud" scheme="https://aaronzhou-whu.github.io/tags/SpringCloud/"/>
    
  </entry>
  
  <entry>
    <title>SpringBootApplication原理</title>
    <link href="https://aaronzhou-whu.github.io/SpringBootApplication%E5%8E%9F%E7%90%86/"/>
    <id>https://aaronzhou-whu.github.io/SpringBootApplication原理/</id>
    <published>2018-10-13T14:47:46.000Z</published>
    <updated>2018-10-13T15:02:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>Springboot项目都有一个启动类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Application</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(Application.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面代码可以看出，@SpringBootApplication注解和SpringApplication.run()方法是关键，所以SpringBoot的启动原理就跟这两个密切相关。</p><h3 id="SpringBootApplication注解"><a href="#SpringBootApplication注解" class="headerlink" title="@SpringBootApplication注解"></a>@SpringBootApplication注解</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Target</span>(ElementType.TYPE)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Inherited</span></span><br><span class="line"><span class="meta">@SpringBootConfiguration</span></span><br><span class="line"><span class="meta">@EnableAutoConfiguration</span></span><br><span class="line"><span class="meta">@ComponentScan</span>(excludeFilters = &#123;</span><br><span class="line">        <span class="meta">@Filter</span>(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),</span><br><span class="line">        <span class="meta">@Filter</span>(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> SpringBootApplication &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中最重要的三个Annotation是：</p><ul><li><p>@Configuration</p></li><li><p>@EnableAutoConfiguration</p></li><li><p>@ComponentScan</p></li></ul><p><strong>@Configuration</strong><br>它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。 </p><p><strong>@EnableAutoConfiguration</strong><br>@EnableAutoConfiguration这个Annotation最为重要，和Spring框架提供的各种名字为@Enable开头的Annotation定义，比如@EnableScheduling、@EnableCaching、@EnableMBeanExport等类似，@EnableAutoConfiguration的理念和做事方式其实一脉相承，简单概括一下就是，借助@Import的支持，收集和注册特定场景相关的bean定义。</p><p>@EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。<br>@EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。<br>而@EnableAutoConfiguration也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器，仅此而已！</p><p><strong>@ComponentScan</strong><br>@ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。</p><p>我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Springboot项目都有一个启动类：&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;li
      
    
    </summary>
    
    
      <category term="Springboot" scheme="https://aaronzhou-whu.github.io/tags/Springboot/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性之Raft</title>
    <link href="https://aaronzhou-whu.github.io/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E4%B9%8BRaft/"/>
    <id>https://aaronzhou-whu.github.io/分布式一致性之Raft/</id>
    <published>2018-10-01T15:04:12.000Z</published>
    <updated>2018-10-01T15:20:34.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前言：</strong><br>分布式系统相对于单机系统，除了提升整个系统的性能外，其他优势还包括具有更好地<strong>容错性</strong>和<strong>可靠性</strong>，提供可靠性可以理解为系统中一台或多台的机器故障不会使系统不可用（或者丢失数据）。<br>保证系统可靠性的关键就是多副本（即数据需要有备份），一旦有多副本，那么就面临多副本之间的一致性问题。<br>一致性算法正是用于解决分布式环境下多副本之间数据一致性的问题的。</p><ul><li><h3 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h3><p>在Raft中，节点有三种角色：</p><ul><li>Leader：负责接收客户端的请求，将日志复制到其他节点并告知其他节点何时应用这些日志是安全的</li><li>Candidate：用于选举Leader的一种角色</li><li>Follower：负责响应来自Leader或者Candidate的请求</li></ul><p>1.所有节点初始状态都是Follower角色<br>2.超时时间内没有收到Leader的请求则转换为Candidate进行选举<br>3.Candidate收到大多数节点的选票则转换为Leader；发现Leader或者收到更高任期的请求则转换为Follower<br>4.Leader在收到更高任期的请求后转换为Follower</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;前言：&lt;/strong&gt;&lt;br&gt;分布式系统相对于单机系统，除了提升整个系统的性能外，其他优势还包括具有更好地&lt;strong&gt;容错性&lt;/strong&gt;和&lt;strong&gt;可靠性&lt;/strong&gt;，提供可靠性可以理解为系统中一台或多台的机器故障不会使系统不可用（或
      
    
    </summary>
    
    
      <category term="Distribution" scheme="https://aaronzhou-whu.github.io/tags/Distribution/"/>
    
  </entry>
  
  <entry>
    <title>count（1）、count（*）与count（列名）的执行区别</title>
    <link href="https://aaronzhou-whu.github.io/count%EF%BC%881%EF%BC%89%E3%80%81count%EF%BC%88*%EF%BC%89%E4%B8%8Ecount%EF%BC%88%E5%88%97%E5%90%8D%EF%BC%89%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>https://aaronzhou-whu.github.io/count（1）、count（*）与count（列名）的区别/</id>
    <published>2018-09-26T01:34:04.000Z</published>
    <updated>2018-09-26T01:36:29.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>执行效果上</strong>： </p><p><strong>count(*)包括了所有的列，相当于行数</strong>，在统计结果的时候，<strong>不会忽略列值为NULL。   </strong></p><p><strong>count(1)</strong>包括了忽略所有列，用1代表代码行，在统计结果的时候，<strong>不会忽略列值为NULL</strong>。 </p><p><strong>count(列名)</strong>只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，<strong>即某个字段值为NULL时，不统计</strong>。</p><p><strong>执行效率上：</strong><br> 列名为主键，count(列名)会比count(1)快<br> 列名不为主键，count(1)会比count(列名)快<br> 如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（<em>）<br> 如果有主键，则 select count（主键）的执行效率是最优的<br> 如果表只有一个字段，则 select count（</em>）最优。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;执行效果上&lt;/strong&gt;： &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;count(*)包括了所有的列，相当于行数&lt;/strong&gt;，在统计结果的时候，&lt;strong&gt;不会忽略列值为NULL。   &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;count(1)&lt;
      
    
    </summary>
    
    
      <category term="MySQL" scheme="https://aaronzhou-whu.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>单进程单线程、单进程多线程和多进程单线程</title>
    <link href="https://aaronzhou-whu.github.io/%E5%8D%95%E8%BF%9B%E7%A8%8B%E5%8D%95%E7%BA%BF%E7%A8%8B%E3%80%81%E5%8D%95%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%8D%95%E7%BA%BF%E7%A8%8B/"/>
    <id>https://aaronzhou-whu.github.io/单进程单线程、单进程多线程和多进程单线程/</id>
    <published>2018-09-19T14:39:56.000Z</published>
    <updated>2018-09-19T15:36:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>我们都知道多线程可以充分利用CPU的性能，毕竟目前都是多核的，而且可以将一些I/O操作另起一个线程，避免当前线程阻塞。</p><p>但是Redis是单线程模型，也就是说不管多少个客户端连接上同一个Redis实例，它都是有一个线程来处理读写请求，严格来说这种模式是单进程单线程。那为什么Redis还是那么快呢？</p><ol><li>完全基于内存</li><li>数据结构简单</li><li>使用多路 I/O 复用模型</li></ol><p><strong>多路 I/O 复用模型</strong>是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程，也就是Redis中的单线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗）</p><p><strong>单进程单线程优点</strong></p><ol><li>代码更清晰，处理逻辑更简单</li><li>不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗</li><li>不存在多进程的切换导致消耗CPU</li></ol><p><strong>单进程单线程缺点</strong></p><p>无法充分发挥多核CPU性能——可以通过开启多个Redis实例来利用多核CPU</p><h4 id="多进程单线程模型：Nginx"><a href="#多进程单线程模型：Nginx" class="headerlink" title="多进程单线程模型：Nginx"></a>多进程单线程模型：Nginx</h4><p>其实我对Nginx了解也不多，只知道一点点相关知识。</p><p>不同于Apache，Nginx使用多进程的方法进行任务处理，每个worker进程只有一个线程，单线程循环处理全部监听的事件（是不是也有多路复用的意思在里面，果然技术很多都是相通的），而Apache对每一个连接都会起一个线程去处理。</p><p>通常一个单独的worker进程使用一个处理器核，这样能完全利用多核体系结构，并且避免线程抖动和锁。由于Nginx不为每个连接派生进程或线程，所以内存使用在大多数情况下是很节约并且高效的。同时由于不用频繁的生成和销毁进程或线程，所以Nginx也很节省CPU。</p><h4 id="单进程多线程模型：Memcached、MySQL等"><a href="#单进程多线程模型：Memcached、MySQL等" class="headerlink" title="单进程多线程模型：Memcached、MySQL等"></a>单进程多线程模型：Memcached、MySQL等</h4><p>这个没用过，只知道也是个类似于Redis的一个缓存数据库。</p><p>Memcache可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS。</p><p>只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。</p><p>无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。</p><p><strong>补充：</strong></p><p>多说一句，Memcached是基于libevent的事件处理。Linux内核提供的epoll为开发服务器提供了很大的便利，libevent和libev都是对epoll的封装，nginx自己实现了对epoll的封装。libevent和libev都是知名的Linux系统Ｃ事件驱动编程框架。所以，nginx在Windows上不像Linux快是有很大原因的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们都知道多线程可以充分利用CPU的性能，毕竟目前都是多核的，而且可以将一些I/O操作另起一个线程，避免当前线程阻塞。&lt;/p&gt;
&lt;p&gt;但是Redis是单线程模型，也就是说不管多少个客户端连接上同一个Redis实例，它都是有一个线程来处理读写请求，严格来说这种模式是单进程单线
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>FaaS--下一代服务框架</title>
    <link href="https://aaronzhou-whu.github.io/FaaS-%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/"/>
    <id>https://aaronzhou-whu.github.io/FaaS-下一代服务框架/</id>
    <published>2018-09-16T15:45:03.000Z</published>
    <updated>2018-09-16T16:31:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>和别的同学聊天，听他们的意思，无服务器计算（serverless），或者Function as a Service（Faas）是下一代后端开发的架构趋势。以后的开发人员只要关注业务逻辑即可，对底层的并发、通信啥的都被FaaS给屏蔽了。</p><p>目前公司还正在着手微服务改造呢，也不是说越新的技术就越好，只是感慨一下，跟互联网公司相比，传统行业在技术应用方面，确实还存在一定的滞后性，还是得时时刻刻学习，才能保持竞争力。</p><p>闲话少叙，FaaS到底是个啥东东呢？Cloud computing时代出现了大量XaaS形式的概念，从IaaS(Infrastructure as a Service)、PaaS(Platform as a Service)、SaaS(Software as a Service)到Docker引领的CaaS(Containers as a Service)，目的都是抽象出各种各种软硬件资源为某一服务，将服务提供给开发者使用，这样开发者更能集中精力与业务开发。</p><p>总的来说FaaS的思想是比各种XaaS，以及目前最火的微服务架构的更小的服务粒度。微服务是一个个Service，FaaS是一个个函数Function。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;和别的同学聊天，听他们的意思，无服务器计算（serverless），或者Function as a Service（Faas）是下一代后端开发的架构趋势。以后的开发人员只要关注业务逻辑即可，对底层的并发、通信啥的都被FaaS给屏蔽了。&lt;/p&gt;
&lt;p&gt;目前公司还正在着手微服务
      
    
    </summary>
    
    
      <category term="FAAS Service" scheme="https://aaronzhou-whu.github.io/tags/FAAS-Service/"/>
    
  </entry>
  
  <entry>
    <title>Linux服务器进程CPU使用率超100%排查</title>
    <link href="https://aaronzhou-whu.github.io/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E7%A8%8BCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E8%B6%85100%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <id>https://aaronzhou-whu.github.io/Linux服务器进程CPU使用率超100问题排查/</id>
    <published>2018-09-15T13:43:52.000Z</published>
    <updated>2018-09-15T14:02:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>线上某个进程CPU使用率过高时，定位问题步骤：</p><ol><li>top：找出CPU使用过高的pid</li><li>top -p pid -H：找出进程pid下哪条线程的CPU使用过高的tid</li><li>printf “%x\n” tid：将该tid转换成16进制ox_tid</li><li>jstack pid |grep ox_tid：查看线程的堆栈信息，这时候就可以看看线程到底为何CPU使用率过高</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;线上某个进程CPU使用率过高时，定位问题步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;top：找出CPU使用过高的pid&lt;/li&gt;
&lt;li&gt;top -p pid -H：找出进程pid下哪条线程的CPU使用过高的tid&lt;/li&gt;
&lt;li&gt;printf “%x\n” tid：将该tid转换
      
    
    </summary>
    
    
      <category term="JVM" scheme="https://aaronzhou-whu.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>一致性协议之2PC</title>
    <link href="https://aaronzhou-whu.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%E4%B9%8B2PC/"/>
    <id>https://aaronzhou-whu.github.io/一致性协议之2PC/</id>
    <published>2018-09-12T13:59:54.000Z</published>
    <updated>2018-09-12T14:27:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>在分布式系统中，由于跨网络跨进程，某一个机器节点能知道自己在事务执行过程是否成功，但却不知道别的节点的操作结果。因此，分布式事务需要一个协调者（Coordinator）的东东来统一调度各个分布式节点，这些节点也称为参与者（Participant）。协调者负责调度参与者的行为，并最终决定参与者是否提交事务。</p><h3 id="两阶段提交协议（2PC：Two-Phrase-Commit）"><a href="#两阶段提交协议（2PC：Two-Phrase-Commit）" class="headerlink" title="两阶段提交协议（2PC：Two-Phrase Commit）"></a>两阶段提交协议（2PC：Two-Phrase Commit）</h3><h4 id="第一阶段：发送事务请求"><a href="#第一阶段：发送事务请求" class="headerlink" title="第一阶段：发送事务请求"></a>第一阶段：发送事务请求</h4><ul><li>协调者向所有的参与者发送事务执行请求，并等待参与者反馈事务执行结果</li><li>事务参与者收到请求之后，执行事务，但不提交，并记录Redo和Undo日志</li><li>参与者将自己事务执行情况反馈给协调者</li></ul><h4 id="第二阶段：执行事务提交"><a href="#第二阶段：执行事务提交" class="headerlink" title="第二阶段：执行事务提交"></a>第二阶段：执行事务提交</h4><p>根据参与者的反馈信息，分为两种情况。如果参与者的反馈都是YES，那么可以提交事务；只要有一个反馈是NO或者超时，就中断事务。<br>提交事务：1.协调者发送提交请求commit给参与者；2.参与者收到commit之后执行事务提交；3.完成提交后向协调者发送ACK；4.协调者收到所有ACK，整个事务完成。<br>中断事务：1.协调者发送rollback给参与者；2.参与者根据Undo来回滚；3.完成回滚后发送ACK确认；4.协调者收到所有ACK后，中断事务</p><h4 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h4><p>虽然2PC实现简单，但是有很多不足之处。<br>1.单点问题：整个过程依赖协调者这个角色，如果协调者挂了之后，整个过程无法继续（还有可能引起死锁问题）<br>2.同步阻塞：所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，效率低下<br>3.数据不一致性：假设协调者发出了commit，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在分布式系统中，由于跨网络跨进程，某一个机器节点能知道自己在事务执行过程是否成功，但却不知道别的节点的操作结果。因此，分布式事务需要一个协调者（Coordinator）的东东来统一调度各个分布式节点，这些节点也称为参与者（Participant）。协调者负责调度参与者的行为
      
    
    </summary>
    
    
      <category term="Distribution" scheme="https://aaronzhou-whu.github.io/tags/Distribution/"/>
    
  </entry>
  
  <entry>
    <title>TCP粘包问题</title>
    <link href="https://aaronzhou-whu.github.io/TCP%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/TCP粘包问题/</id>
    <published>2018-09-11T15:04:59.000Z</published>
    <updated>2018-09-12T00:41:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天面试的时候，面试问了一个TCP粘包的问题，说实话还是第一次听到这个词汇，怪自己网络方面的编程还是积累少了。还好在面试官的提示下，答出了一点点…</p><p>先来回顾一下计算机网络的知识 ——<br><strong>TCP</strong> 为了保证可靠传输，尽量减少额外开销（每次发包都要验证），因此采用了流式传输，面向流的传输，相对于面向消息的传输，可以减少发送包的数量，从而减少了额外开销。但是，对于数据传输频繁的程序来讲，使用TCP可能会容易粘包。当然，对接收端的程序来讲，如果机器负荷很重，也会在接收缓冲里粘包。这样，就需要接收端额外拆包，增加了工作量。因此，这个特别适合的是数据要求可靠传输，但是不需要太频繁传输的场合。</p><p><strong>UDP</strong> 由于面向的是消息传输，它把所有接收到的消息都挂接到缓冲区的接受队列中，因此，它对于数据的提取分离就更加方便，但是，它没有粘包机制，因此，当发送数据量较小的时候，就会发生数据包有效载荷较小的情况，也会增加多次发送的系统发送开销（系统调用，写硬件等）和接收开销。</p><h3 id="什么是粘包现象"><a href="#什么是粘包现象" class="headerlink" title="什么是粘包现象"></a>什么是粘包现象</h3><p>TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。</p><h3 id="粘包出现原因"><a href="#粘包出现原因" class="headerlink" title="粘包出现原因"></a>粘包出现原因</h3><ul><li>发送端需要等缓冲区满才发送出去，造成粘包</li><li>接收方不及时接收缓冲区的包，造成多个包接收</li></ul><p>具体点来说：<br><strong>发送方原因</strong><br>TCP默认会使用Nagle算法。而Nagle算法主要做两件事：1）只有上一个分组得到确认，才会发送下一个分组；2）收集多个小分组，在一个确认到来时一起发送。<br>所以，正是Nagle算法造成了发送方有可能造成粘包现象。</p><p><strong>接收方原因</strong><br>TCP接收到分组时，并不会立刻送至应用层处理，或者说，应用层并不一定会立即处理；实际上，TCP将收到的分组保存至接收缓存里，然后应用程序主动从缓存里读收到的分组。这样一来，如果TCP接收分组的速度大于应用程序读分组的速度，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包。</p><p>粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。</p><p>不是所有的粘包现象都需要处理，若传输的数据为不带结构的连续流数据（如文件传输），则不必把粘连的包分开（简称分包）。但在实际工程应用中，传输的数据一般为带结构的数据，这时就需要做分包处理。</p><h3 id="处理粘包现象"><a href="#处理粘包现象" class="headerlink" title="处理粘包现象"></a>处理粘包现象</h3><p>发送方<br>对于发送方造成的粘包现象，我们可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭Nagle算法。TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满。</p><p>接收方<br>TCP并没有处理接收方粘包现象的机制，我们只能在应用层进行处理。</p><p>应用层处理<br>应用层的处理简单易行！并且不仅可以解决接收方造成的粘包问题，还能解决发送方造成的粘包问题。</p><p>解决方法就是循环处理：应用程序在处理从缓存读来的分组时，读完一条数据时，就应该循环读下一条数据，直到所有的数据都被处理；但是如何判断每条数据的长度呢？</p><p>两种途径：<br>1.格式化数据：每条数据有固定的格式（开始符、结束符），这种方法简单易行，但选择开始符和结束符的时候一定要注意每条数据的内部一定不能出现开始符或结束符；<br>2.发送长度：发送每条数据的时候，将数据的长度一并发送，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以根据长度来判断每条数据的开始和结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天面试的时候，面试问了一个TCP粘包的问题，说实话还是第一次听到这个词汇，怪自己网络方面的编程还是积累少了。还好在面试官的提示下，答出了一点点…&lt;/p&gt;
&lt;p&gt;先来回顾一下计算机网络的知识 ——&lt;br&gt;&lt;strong&gt;TCP&lt;/strong&gt; 为了保证可靠传输，尽量减少额
      
    
    </summary>
    
    
      <category term="TCP" scheme="https://aaronzhou-whu.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>redis缓存相关总结</title>
    <link href="https://aaronzhou-whu.github.io/redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"/>
    <id>https://aaronzhou-whu.github.io/redis缓存相关总结/</id>
    <published>2018-09-04T12:09:04.000Z</published>
    <updated>2018-09-04T12:09:47.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。<br>解决思路：</p><ul><li>直接写个缓存刷新页面，上线时手工操作下。</li><li>数据量不大，可以在WEB系统启动的时候加载。</li><li>定时刷新缓存。</li></ul><h3 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h3><p>缓存淘汰的策略有两种：</p><ul><li>定时去清理过期的缓存。</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 </li></ul><p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。1. 预估失效时间2.版本号（必须单调递增，时间戳是最好的选择）3.提供手动清理缓存的接口。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个<strong>不存在的数据</strong>，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。</p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>当缓存服务器重启或者大量缓存集中在某一个时间段失效，所有的查询都落在数据库上，造成了缓存雪崩。</p><ul><li>在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li><li>可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存</li><li>不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀</li><li>做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;缓存预热&quot;&gt;&lt;a href=&quot;#缓存预热&quot; class=&quot;headerlink&quot; title=&quot;缓存预热&quot;&gt;&lt;/a&gt;缓存预热&lt;/h3&gt;&lt;p&gt;缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。&lt;br&gt;解决思路：
      
    
    </summary>
    
    
      <category term="Redis" scheme="https://aaronzhou-whu.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>二叉树相关算法题（续）</title>
    <link href="https://aaronzhou-whu.github.io/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E9%A2%98%EF%BC%88%E7%BB%AD%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/二叉树相关算法题（续）/</id>
    <published>2018-08-28T08:22:58.000Z</published>
    <updated>2018-09-04T12:26:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>接着之前的那一篇文章——<a href="https://aaronzhou-whu.github.io/二叉树相关算法题">二叉树相关算法题</a></p><p>后序遍历（非递归）：<br>public void postOrderTraverse(TreeNode root) {<br>    // 待续…<br>} </p><p>层次遍历：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">levelTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;TreeNode&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.empty())&#123;</span><br><span class="line">            TreeNode tmp = queue.poll();</span><br><span class="line">            System.out.print(ymp.val+<span class="string">"  "</span>);  </span><br><span class="line">            queue.offer(tmp.left);</span><br><span class="line">            queue.offer(tmp.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;接着之前的那一篇文章——&lt;a href=&quot;https://aaronzhou-whu.github.io/二叉树相关算法题&quot;&gt;二叉树相关算法题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;后序遍历（非递归）：&lt;br&gt;public void postOrderTraverse(TreeNode r
      
    
    </summary>
    
    
      <category term="Binary-Tree" scheme="https://aaronzhou-whu.github.io/tags/Binary-Tree/"/>
    
  </entry>
  
  <entry>
    <title>NIO（二）</title>
    <link href="https://aaronzhou-whu.github.io/NIO%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/NIO（二）/</id>
    <published>2018-08-21T10:33:50.000Z</published>
    <updated>2018-08-21T12:57:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇主要记录一些Buffer相关知识点。</p><h3 id="Buffer中的三个重要属性："><a href="#Buffer中的三个重要属性：" class="headerlink" title="Buffer中的三个重要属性："></a>Buffer中的三个重要属性：</h3><blockquote><ul><li>capacity</li><li>position</li><li>limit</li></ul></blockquote><p>position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式，capacity的含义总是一样的。</p><p><strong>capacity</strong> 作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。</p><p><strong>position</strong> 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。</p><p><strong>limit</strong> 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）。</p><p><strong>mark</strong> 下一个要被读或写的元素的索引。位置会自动由相应的 get( )和 put( )函数更新一个备忘位置。调用 mark( )来设定 mark = postion。调用 reset( )设定 position =mark。标记在设定前是未定义的(undefined)。这四个属性之间总是遵循以下关系：0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity 。</p><h3 id="Buffer的类型"><a href="#Buffer的类型" class="headerlink" title="Buffer的类型"></a>Buffer的类型</h3><p>Java NIO 有以下Buffer类型：</p><blockquote><ul><li>ByteBuffer</li><li>CharBuffer</li><li>DoubleBuffer</li><li>FloatBuffer</li><li>IntBuffer</li><li>LongBuffer</li><li>ShortBuffer</li></ul></blockquote><p>不包含StringBuffer和BooleanBuffer，StringBuffer在lang包下面。用的最多的还是ByteBuffer。</p><h3 id="Buffer的基本用法"><a href="#Buffer的基本用法" class="headerlink" title="Buffer的基本用法"></a>Buffer的基本用法</h3><p>使用Buffer读写数据一般遵循以下四个步骤：</p><blockquote><ul><li>写入数据到Buffer</li><li>调用flip()方法</li><li>从Buffer中读取数据</li><li>调用clear()方法或者compact()方法</li></ul></blockquote><p>flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。</p><p>(TBC…)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇主要记录一些Buffer相关知识点。&lt;/p&gt;
&lt;h3 id=&quot;Buffer中的三个重要属性：&quot;&gt;&lt;a href=&quot;#Buffer中的三个重要属性：&quot; class=&quot;headerlink&quot; title=&quot;Buffer中的三个重要属性：&quot;&gt;&lt;/a&gt;Buffer中的三个重要属
      
    
    </summary>
    
    
      <category term="NIO" scheme="https://aaronzhou-whu.github.io/tags/NIO/"/>
    
  </entry>
  
  <entry>
    <title>NIO小结（一）</title>
    <link href="https://aaronzhou-whu.github.io/NIO%E5%B0%8F%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/NIO小结（一）/</id>
    <published>2018-08-19T14:57:29.000Z</published>
    <updated>2018-08-19T15:28:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近看很多分布式框架或者高并发框架，底层通信很多都是基于Netty，而Netty的核心又是NIO（<em>NoneBlocking IO</em> ），是非阻塞的。</p><p>NIO中最主要的是Buffer（缓冲）、Channel（通道）还有Selector（选择器，也叫多路复用器）。</p><p><strong>Buffer</strong>使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆的 DirectByteBuffer 对象作为这块内存的引用进行操作，避免了在 Java 堆和 Native 堆中来回复制数据。在BIO（阻塞IO）中，等待IO的线程必须被阻塞，这样效率会很低，引入Buffer缓冲区，当数据到达时，可以预先被写入缓冲区，再由缓冲区交给线程，因此线程无需阻塞地等待IO。</p><p><strong>Channel</strong>是数据流通的通道，前面提到的Buffer只是数据的缓冲区，那么数据从哪里来以及到哪里去，都会经过一个流通通道。Channel 是对数据的源头和数据目标点流经途径的抽象，在这个意义上和InputStream和OutputStream类似。Buffer和Channel都是配合使用的。</p><p><strong>Selector</strong>，很多高并发通信框架为何可以做到高并发，就是基于selector这种多路复用原理，一个线程可以负责多个channel。首先创建一个elector，然后将channel注册到selector，最后调用 select() 方法获取通道信息，用于判断是否有我们感兴趣的事件已经发生。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看很多分布式框架或者高并发框架，底层通信很多都是基于Netty，而Netty的核心又是NIO（&lt;em&gt;NoneBlocking IO&lt;/em&gt; ），是非阻塞的。&lt;/p&gt;
&lt;p&gt;NIO中最主要的是Buffer（缓冲）、Channel（通道）还有Selector（选择器，也
      
    
    </summary>
    
    
      <category term="NIO" scheme="https://aaronzhou-whu.github.io/tags/NIO/"/>
    
  </entry>
  
  <entry>
    <title>JDK监控和故障处理工具</title>
    <link href="https://aaronzhou-whu.github.io/JDK%E7%9B%91%E6%8E%A7%E5%92%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    <id>https://aaronzhou-whu.github.io/JDK监控和故障处理工具/</id>
    <published>2018-08-13T12:27:54.000Z</published>
    <updated>2018-08-13T12:41:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>系统定位问题的时候通常会用到虚拟机自带的工具，一般有命令行工具和可视化工具。</p><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><table><thead><tr><th>项目</th><th style="text-align:right">价格</th><th style="text-align:center">数量</th></tr></thead><tbody><tr><td>计算机</td><td style="text-align:right">\$1600</td><td style="text-align:center">5</td></tr><tr><td>手机</td><td style="text-align:right">\$12</td><td style="text-align:center">12</td></tr><tr><td>管线</td><td style="text-align:right">\$1</td><td style="text-align:center">234</td></tr></tbody></table><table><thead><tr><th>名称</th><th style="text-align:left">主要作用</th></tr></thead><tbody><tr><td>jps</td><td style="text-align:left">jvm process status tool,显示指定系统内所有的hotspot虚拟机进程</td></tr><tr><td>jstat　　　</td><td style="text-align:left">jvm statistics monitoring tool,用于收集hotspot虚拟机各方面的运行数据</td></tr><tr><td>jinfo　</td><td style="text-align:left">configuration info for java，显示虚拟机配置信息</td></tr><tr><td>jmap</td><td style="text-align:left">memory map for java,生成虚拟机的内存转储快照（heapdump文件）</td></tr><tr><td>jhat</td><td style="text-align:left">jvm heap dump browser，用于分析heapmap文件，它会建立一个http/html服务器让用户可以在浏览器上查看分析结果</td></tr><tr><td>jstack　</td><td style="text-align:left">stack trace for java, 显示虚拟机的线程快照</td></tr></tbody></table><p><strong>jps：虚拟机进程状况工具</strong><br>可以列出正在运行的虚拟机进程，并显示虚拟机执行主类名称以及这些进程的本地虚拟机唯一ID。<br><strong>jstat：虚拟机统计信息监视工具</strong><br>jstat是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾回收、JIT编译等运行数据。<br><strong>jinfo：java配置信息工具</strong><br>jinfo的作用是实时的查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显示指定的参数列表。<br><strong>jmap：java内存映像工具</strong><br>jmap命令用于生成堆转储快照。jmap的作用并不仅仅为了获取dump文件，它还可以查询finalize执行队列、java堆和永久代的详细信息。如空间使用率、当前用的是哪种收集器等。<br><strong>jhat：虚拟机堆转储快照分析工具</strong><br>Sun JDK提供jhat与jmap搭配使用，来分析dump生成的堆快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。<br><strong>jstack：java堆栈跟踪工具</strong><br>jstack命令用于生成虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程死锁、死循环、请求外部资源导致长时间等待等。</p><h3 id="可视化行工具"><a href="#可视化行工具" class="headerlink" title="可视化行工具"></a>可视化行工具</h3><p><strong>JConsole</strong><br>JConsole工具在JDK/bin目录下，启动JConsole后，将自动搜索本机运行的jvm进程，不需要jps命令来查询指定。双击其中一个jvm进程即可开始监控，也可使用“远程进程”来连接远程服务器。</p><p><strong>VisualVM</strong><br>VisualVM是一个集成多个JDK命令行工具的可视化工具。VisualVM基于NetBeans平台开发，它具备了插件扩展功能的特性，通过插件的扩展，可用于显示虚拟机进程及进程的配置和环境信息(jps，jinfo)，监视应用程序的CPU、GC、堆、方法区及线程的信息(jstat、jstack)等。VisualVM在JDK/bin目录下。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;系统定位问题的时候通常会用到虚拟机自带的工具，一般有命令行工具和可视化工具。&lt;/p&gt;
&lt;h3 id=&quot;命令行工具&quot;&gt;&lt;a href=&quot;#命令行工具&quot; class=&quot;headerlink&quot; title=&quot;命令行工具&quot;&gt;&lt;/a&gt;命令行工具&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
      
    
    </summary>
    
    
      <category term="JVM" scheme="https://aaronzhou-whu.github.io/tags/JVM/"/>
    
  </entry>
  
</feed>

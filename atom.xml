<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BinYingの部屋</title>
  
  <subtitle>知之为知之，不知为不知</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://aaronzhou-whu.github.io/"/>
  <updated>2018-07-30T04:12:33.000Z</updated>
  <id>https://aaronzhou-whu.github.io/</id>
  
  <author>
    <name>Aaron Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>mybatis避坑总结（持续更新ing）</title>
    <link href="https://aaronzhou-whu.github.io/mybatis%E9%81%BF%E5%9D%91%E6%80%BB%E7%BB%93%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/mybatis避坑总结（持续更新ing）/</id>
    <published>2018-07-30T02:41:58.000Z</published>
    <updated>2018-07-30T04:12:33.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="坑一：mybatis-找不到映射器xml文件"><a href="#坑一：mybatis-找不到映射器xml文件" class="headerlink" title="坑一：mybatis 找不到映射器xml文件"></a>坑一：mybatis 找不到映射器xml文件</h3><p>项目打包的时候，出现了找不到xml文件的错误，<code>Error parsing SQL Mapper Configuration. Cause: java.io.IOException: Could not find resource xxx/mapper/xxx.xml</code>，我用的绝对路径但是没有加上“file://”，导致出现<code>file not found</code> error。<br>官方文档给出了四种配置方式：相对路径、绝对路径、Mapper路径、Package路径。<br>```xml<br><!-- Using classpath relative resources --></p><p><mappers><br>  <mapper resource="xxx/mapper/xxx.xml"><br></mapper></mappers><br><!-- Using url fully qualified paths --></p><p><mappers><br>  <mapper url="file:///xxx/mappers/xxx.xml"><br></mapper></mappers><br><!-- Using mapper interface classes --></p><p><mappers><br>  <mapper class="org.mybatis.builder.XXXMapper"><br></mapper></mappers><br><!-- Register all interfaces in a package as mappers --></p><p><mappers><br>  <package name="org.mybatis.builder"><br></package></mappers></p><h3 id="坑二：mybatis-批量插入list"><a href="#坑二：mybatis-批量插入list" class="headerlink" title="坑二：mybatis 批量插入list"></a>坑二：mybatis 批量插入list</h3><p>批量写入的时候用foreach collection，mysql和oracle数据库还有细微差别。<br><strong>Oracle:</strong><br>```xml</p><insert id="inserList" parametertype="com.test.aaa"><br>    insert into table_name (name, adress, age)<br>    values<br>    <foreach collection="list" item="item" index="index" separator=","><br>        (select<br>        #{item.name},#{item.adress}, #{item.age}<br>        from dual)<br>    </foreach><br></insert><br><strong>MySQL:</strong><br>```xml<br><insert id="inserList" parametertype="com.test.aaa"><br>    insert into table_name (name, adress, age)<br>    values<br>    <foreach collection="list" item="item" index="index" separator=","><br>        (#{item.name},  #{item.adress},  #{item.age})<br>    </foreach><br></insert>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;坑一：mybatis-找不到映射器xml文件&quot;&gt;&lt;a href=&quot;#坑一：mybatis-找不到映射器xml文件&quot; class=&quot;headerlink&quot; title=&quot;坑一：mybatis 找不到映射器xml文件&quot;&gt;&lt;/a&gt;坑一：mybatis 找不到映射器xml
      
    
    </summary>
    
    
      <category term="MyBatis" scheme="https://aaronzhou-whu.github.io/tags/MyBatis/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle之Titanic</title>
    <link href="https://aaronzhou-whu.github.io/Kaggle%E4%B9%8BTitanic/"/>
    <id>https://aaronzhou-whu.github.io/Kaggle之Titanic/</id>
    <published>2018-07-28T15:47:34.000Z</published>
    <updated>2018-07-29T15:33:14.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.</p></blockquote><hr><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>问题：这个问题很明显是一道分类问题，预测<code>survive or die</code>的二分类问题。<br>方法：逻辑回归(LogisticRegression)、支持向量机(SVM)、CART等</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask
      
    
    </summary>
    
    
      <category term="Kaggle MachineLearning" scheme="https://aaronzhou-whu.github.io/tags/Kaggle-MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>线程池小结</title>
    <link href="https://aaronzhou-whu.github.io/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%B0%8F%E7%BB%93/"/>
    <id>https://aaronzhou-whu.github.io/线程池小结/</id>
    <published>2018-07-13T11:54:39.000Z</published>
    <updated>2018-07-13T12:38:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>至于为什么要用多线程，以及线程池的好处这里就不说了。这周又粗略看了一遍《Java并发编程的艺术》，又了解了一遍多线程以及线程池的相关知识，为什么这里总是提到“又”，那时因为以前看过，看完也不加总结，总是遗忘，此次总结一下，希望遗忘曲线能够延长一些。</p><h3 id="一-Java通过Executors提供四种线程池，分别为："><a href="#一-Java通过Executors提供四种线程池，分别为：" class="headerlink" title="一. Java通过Executors提供四种线程池，分别为："></a>一. Java通过Executors提供四种线程池，分别为：</h3><p><strong>newCachedThreadPool</strong><br>创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。<br>CachedThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例会根据需要，在线程可用时，重用之前构造好的池中线程。这个线程池在执行 大量短生命周期的异步任务时（many short-lived asynchronous task），可以显著提高程序性能。调用 execute 时，可以重用之前已构造的可用线程，如果不存在可用线程，那么会重新创建一个新的线程并将其加入到线程池中。如果线程超过 60 秒还未被使用，就会被中止并从缓存中移除。因此，线程池在长时间空闲后不会消耗任何资源。<br><strong>newFixedThreadPool</strong> 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。<br>FixedThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例会复用 固定数量的线程 处理一个 共享的无边界队列 。任何时间点，最多有 nThreads 个线程会处于活动状态执行任务。如果当所有线程都是活动时，有多的任务被提交过来，那么它会一致在队列中等待直到有线程可用。如果任何线程在执行过程中因为错误而中止，新的线程会替代它的位置来执行后续的任务。所有线程都会一致存于线程池中，直到显式的执行 ExecutorService.shutdown() 关闭。<br><strong>newScheduledThreadPool</strong> 创建一个定长线程池，支持定时及周期性任务执行。<br><strong>newSingleThreadExecutor</strong> 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。<br>SingleThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例只会使用单个工作线程来执行一个无边界的队列。（注意，如果单个线程在执行过程中因为某些错误中止，新的线程会替代它执行后续线程）。它可以保证认为是按顺序执行的，任何时候都不会有多于一个的任务处于活动状态。和 newFixedThreadPool(1) 的区别在于，如果线程遇到错误中止，它是无法使用替代线程的。</p><h3 id="FixedThreadPool-与-CachedThreadPool-特性对比"><a href="#FixedThreadPool-与-CachedThreadPool-特性对比" class="headerlink" title="FixedThreadPool 与 CachedThreadPool 特性对比"></a>FixedThreadPool 与 CachedThreadPool 特性对比</h3><table><thead><tr><th>特性</th><th style="text-align:center">FixedThreadPool</th><th style="text-align:center">CachedThreadPool</th></tr></thead><tbody><tr><td>重用</td><td style="text-align:center">FixedThreadPool 与 CacheThreadPool差不多，也是能 reuse 就用，但不能随时建新的线程</td><td style="text-align:center">缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse ；如果没有，就建一个新的线程加入池中</td></tr><tr><td>池大小</td><td style="text-align:center">可指定 nThreads，固定数量</td><td style="text-align:center">可增长，最大值 Integer.MAX_VALUE</td></tr><tr><td>队列大小</td><td style="text-align:center">无限制</td><td style="text-align:center">无限制</td></tr><tr><td>超时</td><td style="text-align:center">无 IDLE</td><td style="text-align:center">默认60秒 IDLE</td></tr><tr><td>使用场景</td><td style="text-align:center">FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器</td><td style="text-align:center">大量短生命周期的异步任务</td></tr><tr><td>结束</td><td style="text-align:center">不会自动销毁</td><td style="text-align:center">放入 CachedThreadPool 的线程不必担心其结束，超过 TIMEOUT 不活动，其会自动被终止。</td></tr></tbody></table><h3 id="二-ThreadPoolExecutor的重要参数"><a href="#二-ThreadPoolExecutor的重要参数" class="headerlink" title="二. ThreadPoolExecutor的重要参数"></a>二. ThreadPoolExecutor的重要参数</h3><p><strong>corePoolSize：核心线程数</strong><br>核心线程会一直存活，及时没有任务需要执行<br>当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理<br>设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭<br><strong>queueCapacity：任务队列容量（阻塞队列）</strong><br>当核心线程数达到最大时，新任务会放在队列中排队等待执行<br><strong>maxPoolSize：最大线程数</strong><br>当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务<br>当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常<br><strong>keepAliveTime：线程空闲时间</strong><br>当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize<br>如果allowCoreThreadTimeout=true，则会直到线程数量=0<br><strong>allowCoreThreadTimeout：允许核心线程超时</strong><br><strong>rejectedExecutionHandler：任务拒绝处理器</strong><br>1.两种情况会拒绝处理任务：</p><blockquote><ul><li>当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务</li><li>当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务</li></ul></blockquote><p>2.线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常<br>3.ThreadPoolExecutor类有几个内部实现类来处理这类情况：</p><blockquote><ul><li>AbortPolicy 丢弃任务，抛运行时异常</li><li>CallerRunsPolicy 执行任务</li><li>DiscardPolicy 忽视，什么都不会发生</li><li>DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务</li></ul></blockquote><h3 id="三-线程池按以下行为执行任务"><a href="#三-线程池按以下行为执行任务" class="headerlink" title="三. 线程池按以下行为执行任务"></a>三. 线程池按以下行为执行任务</h3><p>1.当线程数小于核心线程数时，创建线程。<br>2.当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。</p><ol><li>当线程数大于等于核心线程数，且任务队列已满<blockquote><ul><li>若线程数小于最大线程数，创建线程</li><li>若线程数等于最大线程数，抛出异常，拒绝任务</li></ul></blockquote></li></ol><h3 id="四-线程池的底层实现"><a href="#四-线程池的底层实现" class="headerlink" title="四. 线程池的底层实现"></a>四. 线程池的底层实现</h3><p>上节中有个参数是queueCapacity，提到queue，必然要提到各种线程池的底层的阻塞队列的实现方式<br><strong>SynchronousQueue——直接提交策略</strong><br>适用于CachedThreadPool。它将任务直接提交给线程而不保持它们。如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求最大的 maximumPoolSize 以避免拒绝新提交的任务（正如CachedThreadPool这个参数的值为Integer.MAX_VALUE）。当任务以超过队列所能处理的量、连续到达时，此策略允许线程具有增长的可能性。吞吐量较高。</p><p><strong>LinkedBlockingQueue——无界队列</strong><br>适用于FixedThreadPool与SingleThreadExcutor。基于链表的阻塞队列，创建的线程数不会超过corePoolSizes（maximumPoolSize值与其一致），当线程正忙时，任务进入队列等待。按照FIFO原则对元素进行排序，吞吐量高于ArrayBlockingQueue。</p><p><strong>ArrayListBlockingQueue——有界队列</strong><br>有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;至于为什么要用多线程，以及线程池的好处这里就不说了。这周又粗略看了一遍《Java并发编程的艺术》，又了解了一遍多线程以及线程池的相关知识，为什么这里总是提到“又”，那时因为以前看过，看完也不加总结，总是遗忘，此次总结一下，希望遗忘曲线能够延长一些。&lt;/p&gt;
&lt;h3 id=&quot;
      
    
    </summary>
    
    
      <category term="multi-thread" scheme="https://aaronzhou-whu.github.io/tags/multi-thread/"/>
    
  </entry>
  
  <entry>
    <title>设计模式整理（一）</title>
    <link href="https://aaronzhou-whu.github.io/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%95%B4%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/设计模式整理（一）/</id>
    <published>2018-07-03T09:27:02.000Z</published>
    <updated>2018-07-04T09:38:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>来公司一年了，最近整理自己的代码，觉得写得好烂，当初只是关注于功能实现，在设计上并没有过多考虑，可维护性可重用性都不高；并且有时候看源码，很多地方都用到了设计模式，说实话看第一遍的时候很多情形下并不知道为什么作者要这么写，是时候重新整理一波设计模式了，希望自己以后写的代码跟别人源码一样优美 O(∩_∩)O哈哈~</p><p>设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。</p><p>设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p><p>总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）。</p><p><strong>创建型模式</strong><br>这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用新的运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。</p><blockquote><ul><li>工厂模式（Factory Pattern）</li><li>抽象工厂模式（Abstract Factory Pattern）</li><li>单例模式（Singleton Pattern）</li><li>建造者模式（Builder Pattern）</li><li>原型模式（Prototype Pattern）</li></ul></blockquote><p><strong>结构型模式</strong><br>这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。</p><blockquote><ul><li>适配器模式（Adapter Pattern）</li><li>桥接模式（Bridge Pattern）</li><li>过滤器模式（Filter、Criteria Pattern）</li><li>组合模式（Composite Pattern）</li><li>装饰器模式（Decorator Pattern）</li><li>外观模式（Facade Pattern）</li><li>享元模式（Flyweight Pattern）</li><li>代理模式（Proxy Pattern）</li></ul></blockquote><p><strong>行为型模式</strong><br>这些设计模式特别关注对象之间的通信。 </p><blockquote><ul><li>责任链模式（Chain of Responsibility Pattern）</li><li>命令模式（Command Pattern）</li><li>解释器模式（Interpreter Pattern）</li><li>迭代器模式（Iterator Pattern）</li><li>中介者模式（Mediator Pattern）</li><li>备忘录模式（Memento Pattern）</li><li>观察者模式（Observer Pattern）</li><li>状态模式（State Pattern）</li><li>空对象模式（Null Object Pattern）</li><li>策略模式（Strategy Pattern）</li><li>模板模式（Template Pattern）</li><li>访问者模式（Visitor Pattern）</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;来公司一年了，最近整理自己的代码，觉得写得好烂，当初只是关注于功能实现，在设计上并没有过多考虑，可维护性可重用性都不高；并且有时候看源码，很多地方都用到了设计模式，说实话看第一遍的时候很多情形下并不知道为什么作者要这么写，是时候重新整理一波设计模式了，希望自己以后写的代码跟
      
    
    </summary>
    
    
      <category term="design patten" scheme="https://aaronzhou-whu.github.io/tags/design-patten/"/>
    
  </entry>
  
  <entry>
    <title>knn算法</title>
    <link href="https://aaronzhou-whu.github.io/knn%E7%AE%97%E6%B3%95/"/>
    <id>https://aaronzhou-whu.github.io/knn算法/</id>
    <published>2018-06-26T15:30:31.000Z</published>
    <updated>2018-06-26T15:33:09.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="machine learning" scheme="https://aaronzhou-whu.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习入门之常见机器学习算法简介</title>
    <link href="https://aaronzhou-whu.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B9%8B%E5%B8%B8%E8%A7%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>https://aaronzhou-whu.github.io/机器学习入门之常见机器学习算法简介/</id>
    <published>2018-06-23T15:20:21.000Z</published>
    <updated>2018-06-23T15:45:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>写在前头：公司最近有个形态选股的项目，根据股票的历史数据，计算出k线相似的股票，并推荐给客户。要用到机器学习相关知识，刚好可以把研究生阶段所学的浅薄知识重拾起来，加以总结。</p><h3 id="常见机器学习算法："><a href="#常见机器学习算法：" class="headerlink" title="常见机器学习算法："></a>常见机器学习算法：</h3><ol><li>决策树（Decision Tree）：在进行逐步应答过程中，典型的决策树分析会使用分层变量或决策节点，例如，可将一个给定用户分类成信用可靠或不可靠。<br>优点：擅长对人、地点、事物的一系列不同特征、品质、特性进行评估<br>场景举例：基于规则的信用评估、赛马结果预测</li><li>支持向量机（Support Vector Machine）：基于超平面（hyperplane），支持向量机可以对数据群进行分类。<br>优点：支持向量机擅长在变量 X 与其它变量之间进行二元分类操作，无论其关系是否是线性的<br>场景举例：新闻分类、手写识别。</li><li>回归（Regression）：回归可以勾画出因变量与一个或多个因变量之间的状态关系。在这个例子中，将垃圾邮件和非垃圾邮件进行了区分。<br>优点：回归可用于识别变量之间的连续关系，即便这个关系不是非常明显<br>场景举例：路面交通流量分析、邮件过滤</li><li>朴素贝叶斯分类（Naive Bayes Classification）：朴素贝叶斯分类器用于计算可能条件的分支概率。每个独立的特征都是「朴素」或条件独立的，因此它们不会影响别的对象。 例如，在一个装有共 5 个黄色和红色小球的罐子里，连续拿到两个黄色小球的概率是多少？从图中最上方分支可见，前后抓取两个黄色小球的概率为 1/10。朴素贝叶斯分类器可以计算多个特征的联合条件概率。<br>优点：对于在小数据集上有显著特征的相关对象，朴素贝叶斯方法可对其进行快速分类<br>场景举例：情感分析、消费者分类</li><li>隐马尔可夫模型（Hidden Markov model）： 显马尔可夫过程是完全确定性的——一个给定的状态经常会伴随另一个状态。交通信号灯就是一个例子。相反，隐马尔可夫模型通过分析可见数据来计算隐藏状态的发生。随后，借助隐藏状态分析，隐马尔可夫模型可以估计可能的未来观察模式。在本例中，高或低气压的概率（这是隐藏状态）可用于预测晴天、雨天、多云天的概率。<br>优点：容许数据的变化性，适用于识别（recognition）和预测操作<br>场景举例：面部表情分析、气象预测</li><li>随机森林（Random forest）：随机森林算法通过使用多个带有随机选取的数据子集的树（tree）改善了决策树的精确性。本例在基因表达层面上考察了大量与乳腺癌复发相关的基因，并计算出复发风险。<br>优点：随机森林方法被证明对大规模数据集和存在大量且有时不相关特征的项（item）来说很有用<br>场景举例：用户流失分析、风险评估时。</li><li>K近邻（KNN K Nearest Neighbour）<br>版本一：在多维特征空间里，一个数据点的类别，与跟它最近的K个数据点的类别，是一样的概率很大。<br>版本二：如果要了解一个人是什么样的，最有可能从他身边的亲人，朋友，邻居的特性中找到答案。比如一个人的亲近的朋友都会打麻将，那么极大可能他也会打麻将。<br>版本三：“近朱者赤，近墨者黑”的概率大于“出淤泥而不染，浊清涟而不妖”。</li><li>K均值（K-Means）<br>在特征空间中，随机选k个中心，其他所有点找到距离最近的中心，形成k个聚类。然后聚类的中心点成为空间中新的中心，其他所有点再次根据距离形成新的聚类。重复这个过程，直到中心不在变化时。</li><li>卷积神经网络（convolutional neural network）：卷积是指来自后续层的权重的融合，可用于标记输出层。<br>优点：当存在非常大型的数据集、大量特征和复杂的分类任务时，卷积神经网络是非常有用的<br>场景举例：图像识别、文本转语音、药物发现</li></ol><h3 id="机器学习解决问题的的一般流程："><a href="#机器学习解决问题的的一般流程：" class="headerlink" title="机器学习解决问题的的一般流程："></a>机器学习解决问题的的一般流程：</h3><p>①选择数据：将你的数据分成三组：训练数据、验证数据和测试数据<br>②模型数据：使用训练数据来构建使用相关特征的模型<br>③验证模型：使用你的验证数据接入你的模型<br>④测试模型：使用你的测试数据检查被验证的模型的表现<br>⑤使用模型：使用完全训练好的模型在新数据上做预测<br>⑥调优模型：使用更多数据、不同的特征或调整过的参数来提升算法的性能表现</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;写在前头：公司最近有个形态选股的项目，根据股票的历史数据，计算出k线相似的股票，并推荐给客户。要用到机器学习相关知识，刚好可以把研究生阶段所学的浅薄知识重拾起来，加以总结。&lt;/p&gt;
&lt;h3 id=&quot;常见机器学习算法：&quot;&gt;&lt;a href=&quot;#常见机器学习算法：&quot; class=
      
    
    </summary>
    
    
      <category term="machine learning" scheme="https://aaronzhou-whu.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>二叉树相关算法题</title>
    <link href="https://aaronzhou-whu.github.io/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/二叉树相关算法题/</id>
    <published>2018-06-07T05:33:51.000Z</published>
    <updated>2018-06-07T05:45:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>二叉树定义：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    TreeNode left;</span><br><span class="line">    TreeNode right;</span><br><span class="line">    TreeNode(<span class="keyword">int</span> x) &#123; val = x; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>先序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">        preOrderTraverse(root.left);  </span><br><span class="line">        preOrderTraverse(root.right);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>先序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    LinkedList&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    TreeNode pNode = root;</span><br><span class="line">    <span class="keyword">while</span> (pNode != <span class="keyword">null</span> || !stack.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            System.out.print(pNode.val+<span class="string">"  "</span>);</span><br><span class="line">            stack.push(pNode);</span><br><span class="line">            pNode = pNode.left;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            TreeNode node = stack.pop();</span><br><span class="line">            pNode = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>中序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse1</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        inOrderTraverse1(root.left);  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">        inOrderTraverse1(root.right);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>中序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse2</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    LinkedList&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    TreeNode pNode = root;  </span><br><span class="line">    <span class="keyword">while</span> (pNode != <span class="keyword">null</span> || !stack.isEmpty()) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (pNode != <span class="keyword">null</span>) &#123;  </span><br><span class="line">            stack.push(pNode);  </span><br><span class="line">            pNode = pNode.left;  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">            TreeNode node = stack.pop();  </span><br><span class="line">            System.out.print(node.val+<span class="string">"  "</span>);  </span><br><span class="line">            pNode = node.right;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        postOrderTraverse(root.left);  </span><br><span class="line">        postOrderTraverse(root.right);  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="comment">// 待续... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二叉树定义：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>python多版本共存下pip安装包问题</title>
    <link href="https://aaronzhou-whu.github.io/python%E5%A4%9A%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98%E4%B8%8Bpip%E5%AE%89%E8%A3%85%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/python多版本共存下pip安装包问题/</id>
    <published>2018-05-14T06:39:33.000Z</published>
    <updated>2018-05-14T07:04:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>现在一般的机器上都默认带有python2.6或2.7，但是有些项目会用到python3.x，大部分人都是安装多版本的python环境，pip install packagename，import packagename，提示:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ModuleNotFoundError: No module named &apos;packagename&apos;</span><br></pre></td></tr></table></figure></p><p>明明packagename已经安装上了,说明python没有找到packagename.so这个文件，找到这个文件，copy到python的site-packages目录下即可。</p><h3 id="step1-找到pip下载的包所在路径"><a href="#step1-找到pip下载的包所在路径" class="headerlink" title="step1 找到pip下载的包所在路径"></a>step1 找到pip下载的包所在路径</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip -V</span><br><span class="line">pip 10.0.1 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)</span><br></pre></td></tr></table></figure><p>/usr/local/lib/python3.6/site-packages 记为path1</p><h3 id="step2-找到当前python所指向的site-packages"><a href="#step2-找到当前python所指向的site-packages" class="headerlink" title="step2 找到当前python所指向的site-packages"></a>step2 找到当前python所指向的site-packages</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> os</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>os.path.dirname(os.__file__)</span><br><span class="line"><span class="string">'/usr/local/python3/lib/python3.6'</span></span><br></pre></td></tr></table></figure><p>/usr/local/python3/lib/python3.6 记为path2</p><h3 id="step3-复制path1路径下的packagename-xx-so文件到path2"><a href="#step3-复制path1路径下的packagename-xx-so文件到path2" class="headerlink" title="step3 复制path1路径下的packagename-xx.so文件到path2"></a>step3 复制path1路径下的packagename-xx.so文件到path2</h3><p>路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp path1/packagename-xx.so path2</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在一般的机器上都默认带有python2.6或2.7，但是有些项目会用到python3.x，大部分人都是安装多版本的python环境，pip install packagename，import packagename，提示:&lt;br&gt;&lt;figure class=&quot;highl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>多线程编程中的三个核心概念</title>
    <link href="https://aaronzhou-whu.github.io/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%89%E4%B8%AA%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/"/>
    <id>https://aaronzhou-whu.github.io/多线程编程中的三个核心概念/</id>
    <published>2018-04-13T02:43:26.000Z</published>
    <updated>2018-06-20T08:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转发自技术世界，原文链接　<a href="http://www.jasongj.com/java/thread_safe/" target="_blank" rel="noopener">http://www.jasongj.com/java/thread_safe/</a></p></blockquote><p>多线程编程中的三个核心概念<br>原子性<br>这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。</p><p>可见性<br>可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。</p><p>顺序性<br>顺序性指的是，程序执行的顺序按照代码的先后顺序执行。</p><h2 id="Java如何保证原子性"><a href="#Java如何保证原子性" class="headerlink" title="Java如何保证原子性"></a>Java如何保证原子性</h2><p>锁和同步</p><p>常用的保证Java操作原子性的工具是锁和同步方法（或者同步代码块）。使用锁，可以保证同一时间只有一个线程能拿到锁，也就保证了同一时间只有一个线程能执行申请锁和释放锁之间的代码。</p><p>与锁类似的是同步方法或者同步代码块。使用非静态同步方法时，锁住的是当前实例；使用静态同步方法时，锁住的是该类的Class对象；使用静态代码块时，锁住的是synchronized关键字后面括号内的对象。下面是同步代码块示例</p><p>无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。</p><p>CAS（compare and swap）</p><p>基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。AtomicInteger使用方法如下。</p><h2 id="Java如何保证可见性"><a href="#Java如何保证可见性" class="headerlink" title="Java如何保证可见性"></a>Java如何保证可见性</h2><p>Java提供了volatile关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。</p><h2 id="Java如何保证顺序性"><a href="#Java如何保证顺序性" class="headerlink" title="Java如何保证顺序性"></a>Java如何保证顺序性</h2><p>上文讲过编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。</p><p>Java中可通过volatile在一定程序上保证顺序性，另外还可以通过synchronized和锁来保证顺序性。</p><p>synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。</p><p>除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为happens-before原则隐式地保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。</p><h2 id="happens-before原则（先行发生原则）"><a href="#happens-before原则（先行发生原则）" class="headerlink" title="happens-before原则（先行发生原则）"></a>happens-before原则（先行发生原则）</h2><p>传递规则：如果操作1在操作2前面，而操作2在操作3前面，则操作1肯定会在操作3前发生。该规则说明了happens-before原则具有传递性<br>锁定规则：一个unlock操作肯定会在后面对同一个锁的lock操作前发生。这个很好理解，锁只有被释放了才会被再次获取<br>volatile变量规则：对一个被volatile修饰的写操作先发生于后面对该变量的读操作<br>程序次序规则：一个线程内，按照代码顺序执行<br>线程启动规则：Thread对象的start()方法先发生于此线程的其它动作<br>线程终结原则：线程的终止检测后发生于线程中其它的所有操作<br>线程中断规则： 对线程interrupt()方法的调用先发生于对该中断异常的获取<br>对象终结规则：一个对象构造先于它的finalize发生<br>volatile适用场景<br>volatile适用于不需要保证原子性，但却需要保证可见性的场景。</p><h2 id="线程安全十万个为什么"><a href="#线程安全十万个为什么" class="headerlink" title="线程安全十万个为什么"></a>线程安全十万个为什么</h2><p>问：平时项目中使用锁和synchronized比较多，而很少使用volatile，难道就没有保证可见性？<br>答：锁和synchronized即可以保证原子性，也可以保证可见性。都是通过保证同一时间只有一个线程执行目标代码段来实现的。</p><p>问：锁和synchronized为何能保证可见性？<br>答：根据JDK 7的Java doc中对concurrent包的说明，一个线程的写结果保证对另外线程的读操作可见，只要该写操作可以由happen-before原则推断出在读操作之前发生。</p><p>The results of a write by one thread are guaranteed to be visible to a read by another thread only if the write operation happens-before the read operation. The synchronized and volatile constructs, as well as the Thread.start() and Thread.join() methods, can form happens-before relationships.</p><p>问：既然锁和synchronized即可保证原子性也可保证可见性，为何还需要volatile？<br>答：synchronized和锁需要通过操作系统来仲裁谁获得锁，开销比较高，而volatile开销小很多。因此在只需要保证可见性的条件下，使用volatile的性能要比使用锁和synchronized高得多。</p><p>问：既然锁和synchronized可以保证原子性，为什么还需要AtomicInteger这种的类来保证原子操作？<br>答：锁和synchronized需要通过操作系统来仲裁谁获得锁，开销比较高，而AtomicInteger是通过CPU级的CAS操作来保证原子性，开销比较小。所以使用AtomicInteger的目的还是为了提高性能。</p><p>问：还有没有别的办法保证线程安全<br>答：有。尽可能避免引起非线程安全的条件——共享变量。如果能从设计上避免共享变量的使用，即可避免非线程安全的发生，也就无须通过锁或者synchronized以及volatile解决原子性、可见性和顺序性的问题。</p><p>问：synchronized即可修饰非静态方式，也可修饰静态方法，还可修饰代码块，有何区别<br>答：synchronized修饰非静态同步方法时，锁住的是当前实例；synchronized修饰静态同步方法时，锁住的是该类的Class对象；synchronized修饰静态代码块时，锁住的是synchronized关键字后面括号内的对象。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文转发自技术世界，原文链接　&lt;a href=&quot;http://www.jasongj.com/java/thread_safe/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.jasongj.com/java
      
    
    </summary>
    
    
      <category term="多线程" scheme="https://aaronzhou-whu.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>常见的几种概率名词</title>
    <link href="https://aaronzhou-whu.github.io/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E7%A7%8D%E6%A6%82%E7%8E%87%E5%90%8D%E8%AF%8D/"/>
    <id>https://aaronzhou-whu.github.io/常见的几种概率名词/</id>
    <published>2018-04-02T16:02:23.000Z</published>
    <updated>2018-04-02T16:05:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然<br>总是容易搞混，这里总结一下常规的叫法：</p><p><strong>先验概率：</strong><br>事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单独事件概率，如P(x),P(y)。</p><p><strong>后验概率：</strong><br>事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。</p><p><strong>条件概率：</strong><br>一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件下x发生的概率。</p><p><strong>贝叶斯公式：</strong><br>P(y|x) = ( P(x|y) * P(y) ) / P(x)</p><p>这里：<br>P(y|x) 是后验概率，一般是我们求解的目标。</p><p>P(x|y) 是条件概率，又叫似然概率，一般是通过历史数据统计得到。一般不把它叫做先验概率，但从定义上也符合先验定义。</p><p>P(y) 是先验概率，一般都是人主观给出的。贝叶斯中的先验概率一般特指它。</p><p>P(x) 其实也是先验概率，只是在贝叶斯的很多应用中不重要（因为只要最大后验不求绝对值），需要时往往用全概率公式计算得到。</p><p>实例：假设y是文章种类，是一个枚举值；x是向量，表示文章中各个单词的出现次数。</p><p>在拥有训练集的情况下，显然除了后验概率P(y|x)中的x来自一篇新文章无法得到，p(x),p(y),p(x|y)都是可以在抽样集合上统计出的。</p><p><strong>最大似然理论：</strong></p><p>认为P(x|y)最大的类别y，就是当前文档所属类别。即Max P(x|y) = Max p(x1|y)<em>p(x2|y)</em>…p(xn|y), for all y</p><p><strong>贝叶斯理论：</strong></p><p>认为需要增加先验概率p(y)，因为有可能某个y是很稀有的类别几千年才看见一次，即使P(x|y)很高，也很可能不是它。</p><p>所以y = Max P(x|y) * P(y), 其中p(y)一般是数据集里统计出来的。</p><p>从上例来讲，贝叶斯理论显然更合理一些；但实际中很多先验概率是拍脑袋得出的（不准），有些甚至是为了方便求解方便生造出来的（硬凑），那有先验又有什么好处呢？一般攻击贝叶斯都在于这一点</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然&lt;br&gt;总是容易搞混，这里总结一下常规的叫法：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;先验概率：&lt;/strong&gt;&lt;br&gt;事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>一致性哈希</title>
    <link href="https://aaronzhou-whu.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"/>
    <id>https://aaronzhou-whu.github.io/一致性哈希/</id>
    <published>2018-03-28T05:35:08.000Z</published>
    <updated>2018-06-20T08:00:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>均衡性：哈希的结果能够尽可能分布到所有的缓存中去。</p><p>单调性：当缓冲区大小变化时一致性哈希尽量保护已分配的内容不会被重新映射到新缓冲区。</p><p>分散性：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。</p><p>负载：另一个维度的分散性问题，对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。</p><p>首先，求出每个服务器的hash值，将其配置到一个 0~2^n 的圆环上（n通常取32）；<br>其次，用同样的方法求出待存储对象的主键 hash值，也将其配置到这个圆环上；<br>再次，从数据映射到的位置开始顺时针查找，将数据分布到找到的第一个服务器节点上。一致性hash的优点在于加入和删除节点时只会影响到在哈希环中相邻的节点，而对其他节点没有影响。</p><p>平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。hash 算法并不是保证绝对的平衡，<br>为了解决这种情况， consistent hashing 引入了“虚拟节点”的概念，它可以如下定义：<br>“虚拟节点”（ virtual node ）是实际节点在 hash 空间的复制品（ replica ），一实际个节点对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以 hash 值排列。</p><p>ps:摘选自网上很多blog，谢谢他们！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;均衡性：哈希的结果能够尽可能分布到所有的缓存中去。&lt;/p&gt;
&lt;p&gt;单调性：当缓冲区大小变化时一致性哈希尽量保护已分配的内容不会被重新映射到新缓冲区。&lt;/p&gt;
&lt;p&gt;分散性：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://aaronzhou-whu.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>流式计算框架--Storm</title>
    <link href="https://aaronzhou-whu.github.io/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-Storm/"/>
    <id>https://aaronzhou-whu.github.io/流式计算框架-Storm/</id>
    <published>2018-03-16T07:50:46.000Z</published>
    <updated>2018-03-16T08:23:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>Storm是一个分布式的，可靠的，容错的数据流处理系统。它是一个流式计算框架，时延低，无状态的，它通过Apache ZooKeeper管理分布式环境和集群状态，适合实时计算。</p><p>Apache Storm的组件：<br>| 组件 | 描述 |<br>| :-: |  |<br>| Tuple     | 它是有序元素的列表，一组逗号分隔的值，Tuple支持所有数据类型，并传递到Storm集群 |<br>| Stream        |   流是元组的无序序列  |<br>| Spouts        |   Storm从原始数据源（如 Kafka队列，Kestrel队列等）接受输入数据  |<br>| Bolts        |Bolts是逻辑处理单元，接收spout的输入，并产生新的数据流   |</p><p>Storm集群概念：<br>| 组件 | 描述 |<br>| :- | :- |<br>|Nimbus（主节点）|    Nimbus是Storm集群的主节点。集群中的所有其他节点称为工作节点。主节点负责在所有工作节点之间分发数据，向工作节点分配任务和监视故障。|<br>|Supervisor（工作节点）|    遵循指令的节点被称为Supervisors。Supervisor有多个工作进程，它管理工作进程以完成由nimbus分配的任务。|<br>|Worker process（工作进程）|    工作进程将执行与特定拓扑相关的任务。工作进程不会自己运行任务，而是创建执行器并要求他们执行特定的任务。工作进程将有多个执行器。|<br>|Executor（执行者）|执行器只是工作进程产生的单个线程。执行器运行一个或多个任务，但仅用于特定的spout或bolt。|<br>|Task（任务）|任务执行实际的数据处理。所以，它是一个spout或bolt。|<br>|ZooKeeper framework（ZooKeeper框架）|Apache的ZooKeeper的是使用群集（节点组）自己和维护具有强大的同步技术共享数据之间进行协调的服务。Nimbus是无状态的，所以它依赖于ZooKeeper来监视工作节点的状态。ZooKeeper的帮助supervisor与nimbus交互。它负责维持nimbus，supervisor的状态。|</p><p>Apache Storm的工作流程 −</p><ol><li>nimbus接收到提交的“Storm拓扑”，并将任务分配给所有的supervisors</li><li>在特定的时间间隔，所有supervisor将向nimbus发送心跳以通知它们仍然运行着。</li><li>当nimbus检测不到supervisor的心跳时，会将任务分配给另一个supervisor。</li><li>当nimbus本身终止时，supervisor将在没有任何问题的情况下对已经分配的任务进行工作。</li><li>一旦所有的任务都完成后，supervisor将等待新的任务进去；同时，nimbus将由服务监控工具自动重新启动。</li><li>由于网络管理程序和supervisor都可以自动重新启动，并且两者将像以前一样继续，因此Storm保证至少处理所有任务一次。</li><li>一旦处理了所有拓扑，则网络管理器等待新的拓扑到达，并且类似地，管理器等待新的任务。</li></ol><p>默认情况下，Storm集群中有两种模式：</p><blockquote><ul><li>本地模式 -此模式用于开发，测试和调试，因为它是查看所有拓扑组件协同工作的最简单方法。在这种模式下，我们可以调整参数，使我们能够看到我们的拓扑如何在不同的Storm配置环境中运行。在本地模式下，storm拓扑在本地机器上在单个JVM中运行。</li><li>生产模式 -在这种模式下，我们将拓扑提交到工作Storm集群，该集群由许多进程组成，通常运行在不同的机器上。如在storm的工作流中所讨论的，工作集群将无限地运行，直到它被关闭。</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Storm是一个分布式的，可靠的，容错的数据流处理系统。它是一个流式计算框架，时延低，无状态的，它通过Apache ZooKeeper管理分布式环境和集群状态，适合实时计算。&lt;/p&gt;
&lt;p&gt;Apache Storm的组件：&lt;br&gt;| 组件 | 描述 |&lt;br&gt;| :-: |
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Dubbo学习笔记（一）</title>
    <link href="https://aaronzhou-whu.github.io/Dubbo%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/Dubbo学习笔记（一）/</id>
    <published>2018-03-12T15:54:17.000Z</published>
    <updated>2018-03-12T15:54:17.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>大数据处理框架简介</title>
    <link href="https://aaronzhou-whu.github.io/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6/"/>
    <id>https://aaronzhou-whu.github.io/流式计算框架/</id>
    <published>2018-03-10T14:49:45.000Z</published>
    <updated>2018-03-16T07:52:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>大数据处理框架比较常见的又hadoop、spark以及storm。Hadoop是基于HDFS的，数据都存储在磁盘上，io开销比较大；storm是基于内存的，使用zeroMQ消息中间件传递消息，速度比较快。</p><blockquote><ul><li>Hadoop M/R基于HDFS，需要切分输入数据、产生中间数据文件、排序、数据压缩、多份复制等，效率较低。</li><li>Storm 基于ZeroMQ高性能的消息中间件，不持久化数据，效率高。</li><li>Spark基于Map Reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的Map Reduce的算法</li></ul></blockquote><p>Hadoop适合于离线的批量数据处理适用于对实时性要求极低的场景;Storm适合于实时流数据处理，实时性方面做得极好;Spark介于二者之间，批处理方面性能优于Map-Reduce，（Spark streaming）流处理目前弱于Storm。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;大数据处理框架比较常见的又hadoop、spark以及storm。Hadoop是基于HDFS的，数据都存储在磁盘上，io开销比较大；storm是基于内存的，使用zeroMQ消息中间件传递消息，速度比较快。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Hadoop M
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>消息中间件</title>
    <link href="https://aaronzhou-whu.github.io/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    <id>https://aaronzhou-whu.github.io/消息中间件/</id>
    <published>2018-03-09T15:13:34.000Z</published>
    <updated>2018-03-12T15:50:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>在分布式系统中，不同的应用之间需要传递和接收消息（message），消息中间件就是为了解决分布式系统之间的通信。它的异步性方便了对系统进行解耦。<br>在Java邻域，熟知的有JMS（Java Message Service），Java消息服务是一个Java平台中关于面向消息中间件（Message oriented middleware,MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 </p><p>在JMS中，有queue和topic两种模型，点对点（point to point， queue）与发布订阅（publish/subscribe，topic），这两种模式主要区别或解决的问题就是发送到队列的消息能否重复消费(多订阅)。</p><p>目前市面上使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。对比如下：<br><img src="http://img.blog.csdn.net/20171027100748177?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMzEyMzYzNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br>kafka有别于JMS规范或其他分布式消息系统的不同之一，kafka支持将消息持久化处理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在分布式系统中，不同的应用之间需要传递和接收消息（message），消息中间件就是为了解决分布式系统之间的通信。它的异步性方便了对系统进行解耦。&lt;br&gt;在Java邻域，熟知的有JMS（Java Message Service），Java消息服务是一个Java平台中关于面向消
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>谈谈微服务架构</title>
    <link href="https://aaronzhou-whu.github.io/%E8%B0%88%E8%B0%88%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/"/>
    <id>https://aaronzhou-whu.github.io/谈谈微服务架构/</id>
    <published>2018-03-08T15:30:21.000Z</published>
    <updated>2018-03-16T09:08:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>现在</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Java中间件之我的浅显理解</title>
    <link href="https://aaronzhou-whu.github.io/Java%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%B9%8B%E6%88%91%E7%9A%84%E6%B5%85%E6%98%BE%E7%90%86%E8%A7%A3/"/>
    <id>https://aaronzhou-whu.github.io/Java中间件之我的浅显理解/</id>
    <published>2018-03-07T15:17:37.000Z</published>
    <updated>2018-03-08T13:15:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>中间件（middleware），从字面上来看，是不同的系统或程序之间的中间人，是一种交互媒介（通道），中间件屏蔽了各自的细节，方便不同的系统更加关注于彼此的业务。</p><blockquote><p>百度百科上的解释：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源。中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。是连接两个独立应用程序或独立系统的软件。相连接的系统，即使它们具有不同的接口，但通过中间件相互之间仍能交换信息。执行中间件的一个关键途径是信息传递。通过中间件，应用程序可以工作于多平台或OS环境。</p></blockquote><p>Java中间件常见的三个邻域：</p><blockquote><ul><li>远程过程调用和对象访问中间件</li></ul></blockquote><p>主要解决分布式环境下应用的互相访问问题，这也是支撑应用服务化功能的基础。例如：RPC：Remote Process Call（远程过程调用中间件）</p><blockquote><ul><li>消息中间件</li></ul></blockquote><p>解决应用之间的消息传递、解耦、异步的问题。kafka,activeMQ等。</p><blockquote><ul><li>数据访问中间件</li></ul></blockquote><p>Atlas,Cobar等（mysql数据库）。底层的数据查询过程对于调用者来说是透明的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;中间件（middleware），从字面上来看，是不同的系统或程序之间的中间人，是一种交互媒介（通道），中间件屏蔽了各自的细节，方便不同的系统更加关注于彼此的业务。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;百度百科上的解释：中间件是一种独立的系统软件或服务程序，分布式应用软件
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>异常处理小结</title>
    <link href="https://aaronzhou-whu.github.io/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%B0%8F%E7%BB%93/"/>
    <id>https://aaronzhou-whu.github.io/异常处理小结/</id>
    <published>2018-03-06T15:01:12.000Z</published>
    <updated>2018-03-07T11:44:15.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>try catch finally语句块中含有return时的执行顺序：finally会在try代码块的return之前执行</p></li><li><p>try中的return如果是普通变量，则finally语句块中对该变量的修改并不会影响到最终的return值；如果是对象类型，则会影响</p></li><li><p>finally中如果有return语句，则会覆盖掉之前的return返回值</p></li><li><p>如果catch块中捕获了异常, 并且在catch块中将该异常throw给上级调用者进行处理, 但finally中return了, 那么catch块中的throw就失效了, 上级方法调用者是捕获不到异常的–<strong>finally中的return会覆盖掉catch中抛出的异常</strong></p></li><li><p>1.6中catch throw e并且函数要throws Exception，而1.8中只需在catch中throw即可</p></li><li><p>参考链接<a href="https://www.jianshu.com/p/36692cb517bc" target="_blank" rel="noopener">https://www.jianshu.com/p/36692cb517bc</a></p></li><li>参考链接<a href="https://www.cnblogs.com/wyisprogramming/p/6610950.html" target="_blank" rel="noopener">https://www.cnblogs.com/wyisprogramming/p/6610950.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;try catch finally语句块中含有return时的执行顺序：finally会在try代码块的return之前执行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;try中的return如果是普通变量，则finally语句块中对该变量的修改并不会影响到最终的r
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>linux系统上程序OOM问题排查与解决方案</title>
    <link href="https://aaronzhou-whu.github.io/linux%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%A8%8B%E5%BA%8FOOM%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <id>https://aaronzhou-whu.github.io/linux系统上程序OOM问题排查/</id>
    <published>2018-02-26T15:10:00.000Z</published>
    <updated>2018-03-05T16:04:47.000Z</updated>
    
    <content type="html"><![CDATA[<p>Linux上的redis服务器，写数据时发现数据写的不完整，很多没写进去，看日子发现报错：SocketException: Broken pipe (Write failed) ，这种错误一般都是redis挂掉了吧，重启redis，重复执行程序，还是会报错，调试代码，运行少量数据（任然是多线程起任务），发现可以完整写入，那应该不是并发的问题，单机redis挂掉，不是因为并发引起的阻塞timeout，那很有可能是空间不足了，毕竟是测试环境，硬件一般。检查redis的配置文件，找到rdb备份文件，du命令查看占用的存储空间，发现果然满了，去/var/log/message下查看系统日志，找到了“kernel: Out of memory: Kill process”字样。</p><p>du命令查看发现home目录空间严重不足，解决方法一是关闭redis持久化，这种方法在实际应用时是不可取的，只是在测试环境中作为一个临时方案；二是把redis的备份文件目录设置到其他大的空间目录下。</p><p>总的来说，单机redis问题多多，稳定性太差，可以使用基于redis集群方案实现的codis。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Linux上的redis服务器，写数据时发现数据写的不完整，很多没写进去，看日子发现报错：SocketException: Broken pipe (Write failed) ，这种错误一般都是redis挂掉了吧，重启redis，重复执行程序，还是会报错，调试代码，运行少
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>分布式系统简单梳理</title>
    <link href="https://aaronzhou-whu.github.io/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95%E6%A2%B3%E7%90%86/"/>
    <id>https://aaronzhou-whu.github.io/分布式系统简单梳理/</id>
    <published>2018-02-06T15:32:38.000Z</published>
    <updated>2018-02-07T03:01:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>看我最近总是在念叨什么大数据 云计算 分布式之类的，有天 她突然问我什么是大数据 云计算。当时我只是简单地说了几句，这几天工作之余，再重新翻阅相关书籍，整理了一下，算作是一篇科普博文吧。</p><blockquote><ul><li><strong>大数据：</strong> 这个词语太过于宽泛，很多书上都是讲四个V(Volume,Variety,Value,Velocity),简单地理解，就是大量（海量）数据的存储、计算相关技术的总和。</li><li><strong>云计算：</strong> 云计算建立在分布式计算的基础上，只是把它商业化，对外提供服务，更多的语境上，云计算应该是分布式计算的虚拟化以及服务化（virtualization&amp;service）。</li></ul></blockquote><p>不管是大数据还是云计算，要存储或者计算大量数据，没有分布式技术是很难想象的。并且对于一个对架构感兴趣的Java后台开发人员来说，分布式可是必须掌握的。谈到分布式，就必须说说集群了，感觉他们很像孪生兄弟，在我的记忆中，看的书籍或者博客，凡是谈到分布式的都难免要讲讲集群。</p><p>一个程序（任务）跑在一台机器上，这是我们最熟悉的单机系统。当性能不能满足时，我们会堆积多台机器，这些机器就是集群。把一个任务分拆成很多子任务，把这些子任务分别运行在不同的机器上，这就是分布式。显而易见，分布式技术大大提高了运行效率，这个系统也叫做分布式系统。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;看我最近总是在念叨什么大数据 云计算 分布式之类的，有天 她突然问我什么是大数据 云计算。当时我只是简单地说了几句，这几天工作之余，再重新翻阅相关书籍，整理了一下，算作是一篇科普博文吧。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大数据：&lt;/str
      
    
    </summary>
    
    
      <category term="Distributed System" scheme="https://aaronzhou-whu.github.io/tags/Distributed-System/"/>
    
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>BinYingの部屋</title>
  
  <subtitle>知之为知之，不知为不知</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://aaronzhou-whu.github.io/"/>
  <updated>2018-09-15T14:02:41.000Z</updated>
  <id>https://aaronzhou-whu.github.io/</id>
  
  <author>
    <name>Aaron Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux服务器进程CPU使用率超100%排查</title>
    <link href="https://aaronzhou-whu.github.io/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E7%A8%8BCPU%E4%BD%BF%E7%94%A8%E7%8E%87%E8%B6%85100-%E6%8E%92%E6%9F%A5/"/>
    <id>https://aaronzhou-whu.github.io/Linux服务器进程CPU使用率超100-排查/</id>
    <published>2018-09-15T13:43:52.000Z</published>
    <updated>2018-09-15T14:02:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>线上某个进程CPU使用率过高时，定位问题步骤：</p><ol><li>top：找出CPU使用过高的pid</li><li>top -p pid -H：找出进程pid下哪条线程的CPU使用过高的tid</li><li>printf “%x\n” tid：将该tid转换成16进制ox_tid</li><li>jstack pid |grep ox_tid：查看线程的堆栈信息，这时候就可以看看线程到底为何CPU使用率过高</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;线上某个进程CPU使用率过高时，定位问题步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;top：找出CPU使用过高的pid&lt;/li&gt;
&lt;li&gt;top -p pid -H：找出进程pid下哪条线程的CPU使用过高的tid&lt;/li&gt;
&lt;li&gt;printf “%x\n” tid：将该tid转换
      
    
    </summary>
    
    
      <category term="JVM" scheme="https://aaronzhou-whu.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>一致性协议之2PC</title>
    <link href="https://aaronzhou-whu.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE%E4%B9%8B2PC/"/>
    <id>https://aaronzhou-whu.github.io/一致性协议之2PC/</id>
    <published>2018-09-12T13:59:54.000Z</published>
    <updated>2018-09-12T14:27:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>在分布式系统中，由于跨网络跨进程，某一个机器节点能知道自己在事务执行过程是否成功，但却不知道别的节点的操作结果。因此，分布式事务需要一个协调者（Coordinator）的东东来统一调度各个分布式节点，这些节点也称为参与者（Participant）。协调者负责调度参与者的行为，并最终决定参与者是否提交事务。</p><h3 id="两阶段提交协议（2PC：Two-Phrase-Commit）"><a href="#两阶段提交协议（2PC：Two-Phrase-Commit）" class="headerlink" title="两阶段提交协议（2PC：Two-Phrase Commit）"></a>两阶段提交协议（2PC：Two-Phrase Commit）</h3><h4 id="第一阶段：发送事务请求"><a href="#第一阶段：发送事务请求" class="headerlink" title="第一阶段：发送事务请求"></a>第一阶段：发送事务请求</h4><ul><li>协调者向所有的参与者发送事务执行请求，并等待参与者反馈事务执行结果</li><li>事务参与者收到请求之后，执行事务，但不提交，并记录Redo和Undo日志</li><li>参与者将自己事务执行情况反馈给协调者</li></ul><h4 id="第二阶段：执行事务提交"><a href="#第二阶段：执行事务提交" class="headerlink" title="第二阶段：执行事务提交"></a>第二阶段：执行事务提交</h4><p>根据参与者的反馈信息，分为两种情况。如果参与者的反馈都是YES，那么可以提交事务；只要有一个反馈是NO或者超时，就中断事务。<br>提交事务：1.协调者发送提交请求commit给参与者；2.参与者收到commit之后执行事务提交；3.完成提交后向协调者发送ACK；4.协调者收到所有ACK，整个事务完成。<br>中断事务：1.协调者发送rollback给参与者；2.参与者根据Undo来回滚；3.完成回滚后发送ACK确认；4.协调者收到所有ACK后，中断事务</p><h4 id="不足之处"><a href="#不足之处" class="headerlink" title="不足之处"></a>不足之处</h4><p>虽然2PC实现简单，但是有很多不足之处。<br>1.单点问题：整个过程依赖协调者这个角色，如果协调者挂了之后，整个过程无法继续（还有可能引起死锁问题）<br>2.同步阻塞：所有的参与者都需要听从协调者的统一调度，期间处于阻塞状态而不能从事其他操作，效率低下<br>3.数据不一致性：假设协调者发出了commit，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在分布式系统中，由于跨网络跨进程，某一个机器节点能知道自己在事务执行过程是否成功，但却不知道别的节点的操作结果。因此，分布式事务需要一个协调者（Coordinator）的东东来统一调度各个分布式节点，这些节点也称为参与者（Participant）。协调者负责调度参与者的行为
      
    
    </summary>
    
    
      <category term="Distribution" scheme="https://aaronzhou-whu.github.io/tags/Distribution/"/>
    
  </entry>
  
  <entry>
    <title>TCP粘包问题</title>
    <link href="https://aaronzhou-whu.github.io/TCP%E7%B2%98%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/TCP粘包问题/</id>
    <published>2018-09-11T15:04:59.000Z</published>
    <updated>2018-09-12T00:41:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天面试的时候，面试问了一个TCP粘包的问题，说实话还是第一次听到这个词汇，怪自己网络方面的编程还是积累少了。还好在面试官的提示下，答出了一点点…</p><p>先来回顾一下计算机网络的知识 ——<br><strong>TCP</strong> 为了保证可靠传输，尽量减少额外开销（每次发包都要验证），因此采用了流式传输，面向流的传输，相对于面向消息的传输，可以减少发送包的数量，从而减少了额外开销。但是，对于数据传输频繁的程序来讲，使用TCP可能会容易粘包。当然，对接收端的程序来讲，如果机器负荷很重，也会在接收缓冲里粘包。这样，就需要接收端额外拆包，增加了工作量。因此，这个特别适合的是数据要求可靠传输，但是不需要太频繁传输的场合。</p><p><strong>UDP</strong> 由于面向的是消息传输，它把所有接收到的消息都挂接到缓冲区的接受队列中，因此，它对于数据的提取分离就更加方便，但是，它没有粘包机制，因此，当发送数据量较小的时候，就会发生数据包有效载荷较小的情况，也会增加多次发送的系统发送开销（系统调用，写硬件等）和接收开销。</p><h3 id="什么是粘包现象"><a href="#什么是粘包现象" class="headerlink" title="什么是粘包现象"></a>什么是粘包现象</h3><p>TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。</p><h3 id="粘包出现原因"><a href="#粘包出现原因" class="headerlink" title="粘包出现原因"></a>粘包出现原因</h3><ul><li>发送端需要等缓冲区满才发送出去，造成粘包</li><li>接收方不及时接收缓冲区的包，造成多个包接收</li></ul><p>具体点来说：<br><strong>发送方原因</strong><br>TCP默认会使用Nagle算法。而Nagle算法主要做两件事：1）只有上一个分组得到确认，才会发送下一个分组；2）收集多个小分组，在一个确认到来时一起发送。<br>所以，正是Nagle算法造成了发送方有可能造成粘包现象。</p><p><strong>接收方原因</strong><br>TCP接收到分组时，并不会立刻送至应用层处理，或者说，应用层并不一定会立即处理；实际上，TCP将收到的分组保存至接收缓存里，然后应用程序主动从缓存里读收到的分组。这样一来，如果TCP接收分组的速度大于应用程序读分组的速度，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包。</p><p>粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。</p><p>不是所有的粘包现象都需要处理，若传输的数据为不带结构的连续流数据（如文件传输），则不必把粘连的包分开（简称分包）。但在实际工程应用中，传输的数据一般为带结构的数据，这时就需要做分包处理。</p><h3 id="处理粘包现象"><a href="#处理粘包现象" class="headerlink" title="处理粘包现象"></a>处理粘包现象</h3><p>发送方<br>对于发送方造成的粘包现象，我们可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭Nagle算法。TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满。</p><p>接收方<br>TCP并没有处理接收方粘包现象的机制，我们只能在应用层进行处理。</p><p>应用层处理<br>应用层的处理简单易行！并且不仅可以解决接收方造成的粘包问题，还能解决发送方造成的粘包问题。</p><p>解决方法就是循环处理：应用程序在处理从缓存读来的分组时，读完一条数据时，就应该循环读下一条数据，直到所有的数据都被处理；但是如何判断每条数据的长度呢？</p><p>两种途径：<br>1.格式化数据：每条数据有固定的格式（开始符、结束符），这种方法简单易行，但选择开始符和结束符的时候一定要注意每条数据的内部一定不能出现开始符或结束符；<br>2.发送长度：发送每条数据的时候，将数据的长度一并发送，比如可以选择每条数据的前4位是数据的长度，应用层处理时可以根据长度来判断每条数据的开始和结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天面试的时候，面试问了一个TCP粘包的问题，说实话还是第一次听到这个词汇，怪自己网络方面的编程还是积累少了。还好在面试官的提示下，答出了一点点…&lt;/p&gt;
&lt;p&gt;先来回顾一下计算机网络的知识 ——&lt;br&gt;&lt;strong&gt;TCP&lt;/strong&gt; 为了保证可靠传输，尽量减少额
      
    
    </summary>
    
    
      <category term="TCP" scheme="https://aaronzhou-whu.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>redis缓存相关总结</title>
    <link href="https://aaronzhou-whu.github.io/redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/"/>
    <id>https://aaronzhou-whu.github.io/redis缓存相关总结/</id>
    <published>2018-09-04T12:09:04.000Z</published>
    <updated>2018-09-04T12:09:47.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。<br>解决思路：</p><ul><li>直接写个缓存刷新页面，上线时手工操作下。</li><li>数据量不大，可以在WEB系统启动的时候加载。</li><li>定时刷新缓存。</li></ul><h3 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h3><p>缓存淘汰的策略有两种：</p><ul><li>定时去清理过期的缓存。</li><li>当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 </li></ul><p>两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。1. 预估失效时间2.版本号（必须单调递增，时间戳是最好的选择）3.提供手动清理缓存的接口。</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>缓存穿透是指查询一个<strong>不存在的数据</strong>，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。</p><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>当缓存服务器重启或者大量缓存集中在某一个时间段失效，所有的查询都落在数据库上，造成了缓存雪崩。</p><ul><li>在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li><li>可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存</li><li>不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀</li><li>做二级缓存，或者双缓存策略。A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;缓存预热&quot;&gt;&lt;a href=&quot;#缓存预热&quot; class=&quot;headerlink&quot; title=&quot;缓存预热&quot;&gt;&lt;/a&gt;缓存预热&lt;/h3&gt;&lt;p&gt;缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。&lt;br&gt;解决思路：
      
    
    </summary>
    
    
      <category term="Redis" scheme="https://aaronzhou-whu.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>二叉树相关算法题（续）</title>
    <link href="https://aaronzhou-whu.github.io/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E9%A2%98%EF%BC%88%E7%BB%AD%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/二叉树相关算法题（续）/</id>
    <published>2018-08-28T08:22:58.000Z</published>
    <updated>2018-09-04T12:26:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>接着之前的那一篇文章——<a href="https://aaronzhou-whu.github.io/二叉树相关算法题">二叉树相关算法题</a></p><p>后序遍历（非递归）：<br>public void postOrderTraverse(TreeNode root) {<br>    // 待续…<br>} </p><p>层次遍历：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">levelTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;TreeNode&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.empty())&#123;</span><br><span class="line">            TreeNode tmp = queue.poll();</span><br><span class="line">            System.out.print(ymp.val+<span class="string">"  "</span>);  </span><br><span class="line">            queue.offer(tmp.left);</span><br><span class="line">            queue.offer(tmp.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;接着之前的那一篇文章——&lt;a href=&quot;https://aaronzhou-whu.github.io/二叉树相关算法题&quot;&gt;二叉树相关算法题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;后序遍历（非递归）：&lt;br&gt;public void postOrderTraverse(TreeNode r
      
    
    </summary>
    
    
      <category term="Binary-Tree" scheme="https://aaronzhou-whu.github.io/tags/Binary-Tree/"/>
    
  </entry>
  
  <entry>
    <title>NIO（二）</title>
    <link href="https://aaronzhou-whu.github.io/NIO%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/NIO（二）/</id>
    <published>2018-08-21T10:33:50.000Z</published>
    <updated>2018-08-21T12:57:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>这篇主要记录一些Buffer相关知识点。</p><h3 id="Buffer中的三个重要属性："><a href="#Buffer中的三个重要属性：" class="headerlink" title="Buffer中的三个重要属性："></a>Buffer中的三个重要属性：</h3><blockquote><ul><li>capacity</li><li>position</li><li>limit</li></ul></blockquote><p>position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式，capacity的含义总是一样的。</p><p><strong>capacity</strong> 作为一个内存块，Buffer有一个固定的大小值，也叫“capacity”.你只能往里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。</p><p><strong>position</strong> 当你写数据到Buffer中时，position表示当前的位置。初始的position值为0.当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。</p><p><strong>limit</strong> 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 写模式下，limit等于Buffer的capacity。当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）。</p><p><strong>mark</strong> 下一个要被读或写的元素的索引。位置会自动由相应的 get( )和 put( )函数更新一个备忘位置。调用 mark( )来设定 mark = postion。调用 reset( )设定 position =mark。标记在设定前是未定义的(undefined)。这四个属性之间总是遵循以下关系：0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity 。</p><h3 id="Buffer的类型"><a href="#Buffer的类型" class="headerlink" title="Buffer的类型"></a>Buffer的类型</h3><p>Java NIO 有以下Buffer类型：</p><blockquote><ul><li>ByteBuffer</li><li>CharBuffer</li><li>DoubleBuffer</li><li>FloatBuffer</li><li>IntBuffer</li><li>LongBuffer</li><li>ShortBuffer</li></ul></blockquote><p>不包含StringBuffer和BooleanBuffer，StringBuffer在lang包下面。用的最多的还是ByteBuffer。</p><h3 id="Buffer的基本用法"><a href="#Buffer的基本用法" class="headerlink" title="Buffer的基本用法"></a>Buffer的基本用法</h3><p>使用Buffer读写数据一般遵循以下四个步骤：</p><blockquote><ul><li>写入数据到Buffer</li><li>调用flip()方法</li><li>从Buffer中读取数据</li><li>调用clear()方法或者compact()方法</li></ul></blockquote><p>flip方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。</p><p>(TBC…)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这篇主要记录一些Buffer相关知识点。&lt;/p&gt;
&lt;h3 id=&quot;Buffer中的三个重要属性：&quot;&gt;&lt;a href=&quot;#Buffer中的三个重要属性：&quot; class=&quot;headerlink&quot; title=&quot;Buffer中的三个重要属性：&quot;&gt;&lt;/a&gt;Buffer中的三个重要属
      
    
    </summary>
    
    
      <category term="NIO" scheme="https://aaronzhou-whu.github.io/tags/NIO/"/>
    
  </entry>
  
  <entry>
    <title>NIO小结（一）</title>
    <link href="https://aaronzhou-whu.github.io/NIO%E5%B0%8F%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/NIO小结（一）/</id>
    <published>2018-08-19T14:57:29.000Z</published>
    <updated>2018-08-19T15:28:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近看很多分布式框架或者高并发框架，底层通信很多都是基于Netty，而Netty的核心又是NIO（<em>NoneBlocking IO</em> ），是非阻塞的。</p><p>NIO中最主要的是Buffer（缓冲）、Channel（通道）还有Selector（选择器，也叫多路复用器）。</p><p><strong>Buffer</strong>使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆的 DirectByteBuffer 对象作为这块内存的引用进行操作，避免了在 Java 堆和 Native 堆中来回复制数据。在BIO（阻塞IO）中，等待IO的线程必须被阻塞，这样效率会很低，引入Buffer缓冲区，当数据到达时，可以预先被写入缓冲区，再由缓冲区交给线程，因此线程无需阻塞地等待IO。</p><p><strong>Channel</strong>是数据流通的通道，前面提到的Buffer只是数据的缓冲区，那么数据从哪里来以及到哪里去，都会经过一个流通通道。Channel 是对数据的源头和数据目标点流经途径的抽象，在这个意义上和InputStream和OutputStream类似。Buffer和Channel都是配合使用的。</p><p><strong>Selector</strong>，很多高并发通信框架为何可以做到高并发，就是基于selector这种多路复用原理，一个线程可以负责多个channel。首先创建一个elector，然后将channel注册到selector，最后调用 select() 方法获取通道信息，用于判断是否有我们感兴趣的事件已经发生。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近看很多分布式框架或者高并发框架，底层通信很多都是基于Netty，而Netty的核心又是NIO（&lt;em&gt;NoneBlocking IO&lt;/em&gt; ），是非阻塞的。&lt;/p&gt;
&lt;p&gt;NIO中最主要的是Buffer（缓冲）、Channel（通道）还有Selector（选择器，也
      
    
    </summary>
    
    
      <category term="NIO" scheme="https://aaronzhou-whu.github.io/tags/NIO/"/>
    
  </entry>
  
  <entry>
    <title>JDK监控和故障处理工具</title>
    <link href="https://aaronzhou-whu.github.io/JDK%E7%9B%91%E6%8E%A7%E5%92%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/"/>
    <id>https://aaronzhou-whu.github.io/JDK监控和故障处理工具/</id>
    <published>2018-08-13T12:27:54.000Z</published>
    <updated>2018-08-13T12:41:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>系统定位问题的时候通常会用到虚拟机自带的工具，一般有命令行工具和可视化工具。</p><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><table><thead><tr><th>项目</th><th style="text-align:right">价格</th><th style="text-align:center">数量</th></tr></thead><tbody><tr><td>计算机</td><td style="text-align:right">\$1600</td><td style="text-align:center">5</td></tr><tr><td>手机</td><td style="text-align:right">\$12</td><td style="text-align:center">12</td></tr><tr><td>管线</td><td style="text-align:right">\$1</td><td style="text-align:center">234</td></tr></tbody></table><table><thead><tr><th>名称</th><th style="text-align:left">主要作用</th></tr></thead><tbody><tr><td>jps</td><td style="text-align:left">jvm process status tool,显示指定系统内所有的hotspot虚拟机进程</td></tr><tr><td>jstat　　　</td><td style="text-align:left">jvm statistics monitoring tool,用于收集hotspot虚拟机各方面的运行数据</td></tr><tr><td>jinfo　</td><td style="text-align:left">configuration info for java，显示虚拟机配置信息</td></tr><tr><td>jmap</td><td style="text-align:left">memory map for java,生成虚拟机的内存转储快照（heapdump文件）</td></tr><tr><td>jhat</td><td style="text-align:left">jvm heap dump browser，用于分析heapmap文件，它会建立一个http/html服务器让用户可以在浏览器上查看分析结果</td></tr><tr><td>jstack　</td><td style="text-align:left">stack trace for java, 显示虚拟机的线程快照</td></tr></tbody></table><p><strong>jps：虚拟机进程状况工具</strong><br>可以列出正在运行的虚拟机进程，并显示虚拟机执行主类名称以及这些进程的本地虚拟机唯一ID。<br><strong>jstat：虚拟机统计信息监视工具</strong><br>jstat是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾回收、JIT编译等运行数据。<br><strong>jinfo：java配置信息工具</strong><br>jinfo的作用是实时的查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显示指定的参数列表。<br><strong>jmap：java内存映像工具</strong><br>jmap命令用于生成堆转储快照。jmap的作用并不仅仅为了获取dump文件，它还可以查询finalize执行队列、java堆和永久代的详细信息。如空间使用率、当前用的是哪种收集器等。<br><strong>jhat：虚拟机堆转储快照分析工具</strong><br>Sun JDK提供jhat与jmap搭配使用，来分析dump生成的堆快照。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，可以在浏览器中查看。<br><strong>jstack：java堆栈跟踪工具</strong><br>jstack命令用于生成虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程死锁、死循环、请求外部资源导致长时间等待等。</p><h3 id="可视化行工具"><a href="#可视化行工具" class="headerlink" title="可视化行工具"></a>可视化行工具</h3><p><strong>JConsole</strong><br>JConsole工具在JDK/bin目录下，启动JConsole后，将自动搜索本机运行的jvm进程，不需要jps命令来查询指定。双击其中一个jvm进程即可开始监控，也可使用“远程进程”来连接远程服务器。</p><p><strong>VisualVM</strong><br>VisualVM是一个集成多个JDK命令行工具的可视化工具。VisualVM基于NetBeans平台开发，它具备了插件扩展功能的特性，通过插件的扩展，可用于显示虚拟机进程及进程的配置和环境信息(jps，jinfo)，监视应用程序的CPU、GC、堆、方法区及线程的信息(jstat、jstack)等。VisualVM在JDK/bin目录下。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;系统定位问题的时候通常会用到虚拟机自带的工具，一般有命令行工具和可视化工具。&lt;/p&gt;
&lt;h3 id=&quot;命令行工具&quot;&gt;&lt;a href=&quot;#命令行工具&quot; class=&quot;headerlink&quot; title=&quot;命令行工具&quot;&gt;&lt;/a&gt;命令行工具&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
      
    
    </summary>
    
    
      <category term="JVM" scheme="https://aaronzhou-whu.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>mybatis避坑总结（持续更新ing）</title>
    <link href="https://aaronzhou-whu.github.io/mybatis%E9%81%BF%E5%9D%91%E6%80%BB%E7%BB%93%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0ing%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/mybatis避坑总结（持续更新ing）/</id>
    <published>2018-07-30T02:41:58.000Z</published>
    <updated>2018-07-30T10:50:20.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="坑一：mybatis-找不到映射器xml文件"><a href="#坑一：mybatis-找不到映射器xml文件" class="headerlink" title="坑一：mybatis 找不到映射器xml文件"></a>坑一：mybatis 找不到映射器xml文件</h3><p>项目打包的时候，出现了找不到xml文件的错误，<code>Error parsing SQL Mapper Configuration. Cause: java.io.IOException: Could not find resource xxx/mapper/xxx.xml</code>，我用的绝对路径但是没有把resource改为url，导致出现<code>file not found</code> error。<br>官方文档给出了四种配置方式：相对路径、绝对路径、Mapper路径、Package路径。<br>```xml<br><!-- Using classpath relative resources --></p><p><mappers><br>  <mapper resource="xxx/mapper/xxx.xml"><br></mapper></mappers><br><!-- Using url fully qualified paths --></p><p><mappers><br>  <mapper url="file:///xxx/mappers/xxx.xml"><br></mapper></mappers><br><!-- Using mapper interface classes --></p><p><mappers><br>  <mapper class="org.mybatis.builder.XXXMapper"><br></mapper></mappers><br><!-- Register all interfaces in a package as mappers --></p><p><mappers><br>  <package name="org.mybatis.builder"><br></package></mappers></p><h3 id="坑二：mybatis-批量插入list"><a href="#坑二：mybatis-批量插入list" class="headerlink" title="坑二：mybatis 批量插入list"></a>坑二：mybatis 批量插入list</h3><p>批量写入的时候用foreach collection，mysql和oracle数据库还有细微差别。<br><strong>Oracle:</strong><br>```xml</p><insert id="inserList" parametertype="com.test.aaa"><br>    insert into table_name (name, adress, age)<br>    values<br>    <foreach collection="list" item="item" index="index" separator=","><br>        (select<br>        #{item.name},#{item.adress}, #{item.age}<br>        from dual)<br>    </foreach><br></insert><br><strong>MySQL:</strong><br>```xml<br><insert id="inserList" parametertype="com.test.aaa"><br>    insert into table_name (name, adress, age)<br>    values<br>    <foreach collection="list" item="item" index="index" separator=","><br>        (#{item.name},  #{item.adress},  #{item.age})<br>    </foreach><br></insert>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;坑一：mybatis-找不到映射器xml文件&quot;&gt;&lt;a href=&quot;#坑一：mybatis-找不到映射器xml文件&quot; class=&quot;headerlink&quot; title=&quot;坑一：mybatis 找不到映射器xml文件&quot;&gt;&lt;/a&gt;坑一：mybatis 找不到映射器xml
      
    
    </summary>
    
    
      <category term="MyBatis" scheme="https://aaronzhou-whu.github.io/tags/MyBatis/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle之Titanic</title>
    <link href="https://aaronzhou-whu.github.io/Kaggle%E4%B9%8BTitanic/"/>
    <id>https://aaronzhou-whu.github.io/Kaggle之Titanic/</id>
    <published>2018-07-28T15:47:34.000Z</published>
    <updated>2018-07-29T15:33:14.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.</p></blockquote><hr><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>问题：这个问题很明显是一道分类问题，预测<code>survive or die</code>的二分类问题。<br>方法：逻辑回归(LogisticRegression)、支持向量机(SVM)、CART等</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask
      
    
    </summary>
    
    
      <category term="Kaggle MachineLearning" scheme="https://aaronzhou-whu.github.io/tags/Kaggle-MachineLearning/"/>
    
  </entry>
  
  <entry>
    <title>线程池小结</title>
    <link href="https://aaronzhou-whu.github.io/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%B0%8F%E7%BB%93/"/>
    <id>https://aaronzhou-whu.github.io/线程池小结/</id>
    <published>2018-07-13T11:54:39.000Z</published>
    <updated>2018-07-13T12:38:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>至于为什么要用多线程，以及线程池的好处这里就不说了。这周又粗略看了一遍《Java并发编程的艺术》，又了解了一遍多线程以及线程池的相关知识，为什么这里总是提到“又”，那时因为以前看过，看完也不加总结，总是遗忘，此次总结一下，希望遗忘曲线能够延长一些。</p><h3 id="一-Java通过Executors提供四种线程池，分别为："><a href="#一-Java通过Executors提供四种线程池，分别为：" class="headerlink" title="一. Java通过Executors提供四种线程池，分别为："></a>一. Java通过Executors提供四种线程池，分别为：</h3><p><strong>newCachedThreadPool</strong><br>创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。<br>CachedThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例会根据需要，在线程可用时，重用之前构造好的池中线程。这个线程池在执行 大量短生命周期的异步任务时（many short-lived asynchronous task），可以显著提高程序性能。调用 execute 时，可以重用之前已构造的可用线程，如果不存在可用线程，那么会重新创建一个新的线程并将其加入到线程池中。如果线程超过 60 秒还未被使用，就会被中止并从缓存中移除。因此，线程池在长时间空闲后不会消耗任何资源。<br><strong>newFixedThreadPool</strong> 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。<br>FixedThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例会复用 固定数量的线程 处理一个 共享的无边界队列 。任何时间点，最多有 nThreads 个线程会处于活动状态执行任务。如果当所有线程都是活动时，有多的任务被提交过来，那么它会一致在队列中等待直到有线程可用。如果任何线程在执行过程中因为错误而中止，新的线程会替代它的位置来执行后续的任务。所有线程都会一致存于线程池中，直到显式的执行 ExecutorService.shutdown() 关闭。<br><strong>newScheduledThreadPool</strong> 创建一个定长线程池，支持定时及周期性任务执行。<br><strong>newSingleThreadExecutor</strong> 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。<br>SingleThreadPool 是通过 java.util.concurrent.Executors 创建的 ThreadPoolExecutor 实例。这个实例只会使用单个工作线程来执行一个无边界的队列。（注意，如果单个线程在执行过程中因为某些错误中止，新的线程会替代它执行后续线程）。它可以保证认为是按顺序执行的，任何时候都不会有多于一个的任务处于活动状态。和 newFixedThreadPool(1) 的区别在于，如果线程遇到错误中止，它是无法使用替代线程的。</p><h3 id="FixedThreadPool-与-CachedThreadPool-特性对比"><a href="#FixedThreadPool-与-CachedThreadPool-特性对比" class="headerlink" title="FixedThreadPool 与 CachedThreadPool 特性对比"></a>FixedThreadPool 与 CachedThreadPool 特性对比</h3><table><thead><tr><th>特性</th><th style="text-align:center">FixedThreadPool</th><th style="text-align:center">CachedThreadPool</th></tr></thead><tbody><tr><td>重用</td><td style="text-align:center">FixedThreadPool 与 CacheThreadPool差不多，也是能 reuse 就用，但不能随时建新的线程</td><td style="text-align:center">缓存型池子，先查看池中有没有以前建立的线程，如果有，就 reuse ；如果没有，就建一个新的线程加入池中</td></tr><tr><td>池大小</td><td style="text-align:center">可指定 nThreads，固定数量</td><td style="text-align:center">可增长，最大值 Integer.MAX_VALUE</td></tr><tr><td>队列大小</td><td style="text-align:center">无限制</td><td style="text-align:center">无限制</td></tr><tr><td>超时</td><td style="text-align:center">无 IDLE</td><td style="text-align:center">默认60秒 IDLE</td></tr><tr><td>使用场景</td><td style="text-align:center">FixedThreadPool多数针对一些很稳定很固定的正规并发线程，多用于服务器</td><td style="text-align:center">大量短生命周期的异步任务</td></tr><tr><td>结束</td><td style="text-align:center">不会自动销毁</td><td style="text-align:center">放入 CachedThreadPool 的线程不必担心其结束，超过 TIMEOUT 不活动，其会自动被终止。</td></tr></tbody></table><h3 id="二-ThreadPoolExecutor的重要参数"><a href="#二-ThreadPoolExecutor的重要参数" class="headerlink" title="二. ThreadPoolExecutor的重要参数"></a>二. ThreadPoolExecutor的重要参数</h3><p><strong>corePoolSize：核心线程数</strong><br>核心线程会一直存活，及时没有任务需要执行<br>当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理<br>设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭<br><strong>queueCapacity：任务队列容量（阻塞队列）</strong><br>当核心线程数达到最大时，新任务会放在队列中排队等待执行<br><strong>maxPoolSize：最大线程数</strong><br>当线程数&gt;=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务<br>当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常<br><strong>keepAliveTime：线程空闲时间</strong><br>当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize<br>如果allowCoreThreadTimeout=true，则会直到线程数量=0<br><strong>allowCoreThreadTimeout：允许核心线程超时</strong><br><strong>rejectedExecutionHandler：任务拒绝处理器</strong><br>1.两种情况会拒绝处理任务：</p><blockquote><ul><li>当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务</li><li>当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务</li></ul></blockquote><p>2.线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常<br>3.ThreadPoolExecutor类有几个内部实现类来处理这类情况：</p><blockquote><ul><li>AbortPolicy 丢弃任务，抛运行时异常</li><li>CallerRunsPolicy 执行任务</li><li>DiscardPolicy 忽视，什么都不会发生</li><li>DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务</li></ul></blockquote><h3 id="三-线程池按以下行为执行任务"><a href="#三-线程池按以下行为执行任务" class="headerlink" title="三. 线程池按以下行为执行任务"></a>三. 线程池按以下行为执行任务</h3><p>1.当线程数小于核心线程数时，创建线程。<br>2.当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。</p><ol><li>当线程数大于等于核心线程数，且任务队列已满<blockquote><ul><li>若线程数小于最大线程数，创建线程</li><li>若线程数等于最大线程数，抛出异常，拒绝任务</li></ul></blockquote></li></ol><h3 id="四-线程池的底层实现"><a href="#四-线程池的底层实现" class="headerlink" title="四. 线程池的底层实现"></a>四. 线程池的底层实现</h3><p>上节中有个参数是queueCapacity，提到queue，必然要提到各种线程池的底层的阻塞队列的实现方式<br><strong>SynchronousQueue——直接提交策略</strong><br>适用于CachedThreadPool。它将任务直接提交给线程而不保持它们。如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求最大的 maximumPoolSize 以避免拒绝新提交的任务（正如CachedThreadPool这个参数的值为Integer.MAX_VALUE）。当任务以超过队列所能处理的量、连续到达时，此策略允许线程具有增长的可能性。吞吐量较高。</p><p><strong>LinkedBlockingQueue——无界队列</strong><br>适用于FixedThreadPool与SingleThreadExcutor。基于链表的阻塞队列，创建的线程数不会超过corePoolSizes（maximumPoolSize值与其一致），当线程正忙时，任务进入队列等待。按照FIFO原则对元素进行排序，吞吐量高于ArrayBlockingQueue。</p><p><strong>ArrayListBlockingQueue——有界队列</strong><br>有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;至于为什么要用多线程，以及线程池的好处这里就不说了。这周又粗略看了一遍《Java并发编程的艺术》，又了解了一遍多线程以及线程池的相关知识，为什么这里总是提到“又”，那时因为以前看过，看完也不加总结，总是遗忘，此次总结一下，希望遗忘曲线能够延长一些。&lt;/p&gt;
&lt;h3 id=&quot;
      
    
    </summary>
    
    
      <category term="multi-thread" scheme="https://aaronzhou-whu.github.io/tags/multi-thread/"/>
    
  </entry>
  
  <entry>
    <title>设计模式整理（一）</title>
    <link href="https://aaronzhou-whu.github.io/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%95%B4%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://aaronzhou-whu.github.io/设计模式整理（一）/</id>
    <published>2018-07-03T09:27:02.000Z</published>
    <updated>2018-07-04T09:38:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>来公司一年了，最近整理自己的代码，觉得写得好烂，当初只是关注于功能实现，在设计上并没有过多考虑，可维护性可重用性都不高；并且有时候看源码，很多地方都用到了设计模式，说实话看第一遍的时候很多情形下并不知道为什么作者要这么写，是时候重新整理一波设计模式了，希望自己以后写的代码跟别人源码一样优美 O(∩_∩)O哈哈~</p><p>设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。</p><p>设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。</p><p>总共有 23 种设计模式。这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）。</p><p><strong>创建型模式</strong><br>这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用新的运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。</p><blockquote><ul><li>工厂模式（Factory Pattern）</li><li>抽象工厂模式（Abstract Factory Pattern）</li><li>单例模式（Singleton Pattern）</li><li>建造者模式（Builder Pattern）</li><li>原型模式（Prototype Pattern）</li></ul></blockquote><p><strong>结构型模式</strong><br>这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。</p><blockquote><ul><li>适配器模式（Adapter Pattern）</li><li>桥接模式（Bridge Pattern）</li><li>过滤器模式（Filter、Criteria Pattern）</li><li>组合模式（Composite Pattern）</li><li>装饰器模式（Decorator Pattern）</li><li>外观模式（Facade Pattern）</li><li>享元模式（Flyweight Pattern）</li><li>代理模式（Proxy Pattern）</li></ul></blockquote><p><strong>行为型模式</strong><br>这些设计模式特别关注对象之间的通信。 </p><blockquote><ul><li>责任链模式（Chain of Responsibility Pattern）</li><li>命令模式（Command Pattern）</li><li>解释器模式（Interpreter Pattern）</li><li>迭代器模式（Iterator Pattern）</li><li>中介者模式（Mediator Pattern）</li><li>备忘录模式（Memento Pattern）</li><li>观察者模式（Observer Pattern）</li><li>状态模式（State Pattern）</li><li>空对象模式（Null Object Pattern）</li><li>策略模式（Strategy Pattern）</li><li>模板模式（Template Pattern）</li><li>访问者模式（Visitor Pattern）</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;来公司一年了，最近整理自己的代码，觉得写得好烂，当初只是关注于功能实现，在设计上并没有过多考虑，可维护性可重用性都不高；并且有时候看源码，很多地方都用到了设计模式，说实话看第一遍的时候很多情形下并不知道为什么作者要这么写，是时候重新整理一波设计模式了，希望自己以后写的代码跟
      
    
    </summary>
    
    
      <category term="design patten" scheme="https://aaronzhou-whu.github.io/tags/design-patten/"/>
    
  </entry>
  
  <entry>
    <title>knn算法</title>
    <link href="https://aaronzhou-whu.github.io/knn%E7%AE%97%E6%B3%95/"/>
    <id>https://aaronzhou-whu.github.io/knn算法/</id>
    <published>2018-06-26T15:30:31.000Z</published>
    <updated>2018-06-26T15:33:09.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="machine learning" scheme="https://aaronzhou-whu.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学习入门之常见机器学习算法简介</title>
    <link href="https://aaronzhou-whu.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E4%B9%8B%E5%B8%B8%E8%A7%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B/"/>
    <id>https://aaronzhou-whu.github.io/机器学习入门之常见机器学习算法简介/</id>
    <published>2018-06-23T15:20:21.000Z</published>
    <updated>2018-06-23T15:45:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>写在前头：公司最近有个形态选股的项目，根据股票的历史数据，计算出k线相似的股票，并推荐给客户。要用到机器学习相关知识，刚好可以把研究生阶段所学的浅薄知识重拾起来，加以总结。</p><h3 id="常见机器学习算法："><a href="#常见机器学习算法：" class="headerlink" title="常见机器学习算法："></a>常见机器学习算法：</h3><ol><li>决策树（Decision Tree）：在进行逐步应答过程中，典型的决策树分析会使用分层变量或决策节点，例如，可将一个给定用户分类成信用可靠或不可靠。<br>优点：擅长对人、地点、事物的一系列不同特征、品质、特性进行评估<br>场景举例：基于规则的信用评估、赛马结果预测</li><li>支持向量机（Support Vector Machine）：基于超平面（hyperplane），支持向量机可以对数据群进行分类。<br>优点：支持向量机擅长在变量 X 与其它变量之间进行二元分类操作，无论其关系是否是线性的<br>场景举例：新闻分类、手写识别。</li><li>回归（Regression）：回归可以勾画出因变量与一个或多个因变量之间的状态关系。在这个例子中，将垃圾邮件和非垃圾邮件进行了区分。<br>优点：回归可用于识别变量之间的连续关系，即便这个关系不是非常明显<br>场景举例：路面交通流量分析、邮件过滤</li><li>朴素贝叶斯分类（Naive Bayes Classification）：朴素贝叶斯分类器用于计算可能条件的分支概率。每个独立的特征都是「朴素」或条件独立的，因此它们不会影响别的对象。 例如，在一个装有共 5 个黄色和红色小球的罐子里，连续拿到两个黄色小球的概率是多少？从图中最上方分支可见，前后抓取两个黄色小球的概率为 1/10。朴素贝叶斯分类器可以计算多个特征的联合条件概率。<br>优点：对于在小数据集上有显著特征的相关对象，朴素贝叶斯方法可对其进行快速分类<br>场景举例：情感分析、消费者分类</li><li>隐马尔可夫模型（Hidden Markov model）： 显马尔可夫过程是完全确定性的——一个给定的状态经常会伴随另一个状态。交通信号灯就是一个例子。相反，隐马尔可夫模型通过分析可见数据来计算隐藏状态的发生。随后，借助隐藏状态分析，隐马尔可夫模型可以估计可能的未来观察模式。在本例中，高或低气压的概率（这是隐藏状态）可用于预测晴天、雨天、多云天的概率。<br>优点：容许数据的变化性，适用于识别（recognition）和预测操作<br>场景举例：面部表情分析、气象预测</li><li>随机森林（Random forest）：随机森林算法通过使用多个带有随机选取的数据子集的树（tree）改善了决策树的精确性。本例在基因表达层面上考察了大量与乳腺癌复发相关的基因，并计算出复发风险。<br>优点：随机森林方法被证明对大规模数据集和存在大量且有时不相关特征的项（item）来说很有用<br>场景举例：用户流失分析、风险评估时。</li><li>K近邻（KNN K Nearest Neighbour）<br>版本一：在多维特征空间里，一个数据点的类别，与跟它最近的K个数据点的类别，是一样的概率很大。<br>版本二：如果要了解一个人是什么样的，最有可能从他身边的亲人，朋友，邻居的特性中找到答案。比如一个人的亲近的朋友都会打麻将，那么极大可能他也会打麻将。<br>版本三：“近朱者赤，近墨者黑”的概率大于“出淤泥而不染，浊清涟而不妖”。</li><li>K均值（K-Means）<br>在特征空间中，随机选k个中心，其他所有点找到距离最近的中心，形成k个聚类。然后聚类的中心点成为空间中新的中心，其他所有点再次根据距离形成新的聚类。重复这个过程，直到中心不在变化时。</li><li>卷积神经网络（convolutional neural network）：卷积是指来自后续层的权重的融合，可用于标记输出层。<br>优点：当存在非常大型的数据集、大量特征和复杂的分类任务时，卷积神经网络是非常有用的<br>场景举例：图像识别、文本转语音、药物发现</li></ol><h3 id="机器学习解决问题的的一般流程："><a href="#机器学习解决问题的的一般流程：" class="headerlink" title="机器学习解决问题的的一般流程："></a>机器学习解决问题的的一般流程：</h3><p>①选择数据：将你的数据分成三组：训练数据、验证数据和测试数据<br>②模型数据：使用训练数据来构建使用相关特征的模型<br>③验证模型：使用你的验证数据接入你的模型<br>④测试模型：使用你的测试数据检查被验证的模型的表现<br>⑤使用模型：使用完全训练好的模型在新数据上做预测<br>⑥调优模型：使用更多数据、不同的特征或调整过的参数来提升算法的性能表现</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;写在前头：公司最近有个形态选股的项目，根据股票的历史数据，计算出k线相似的股票，并推荐给客户。要用到机器学习相关知识，刚好可以把研究生阶段所学的浅薄知识重拾起来，加以总结。&lt;/p&gt;
&lt;h3 id=&quot;常见机器学习算法：&quot;&gt;&lt;a href=&quot;#常见机器学习算法：&quot; class=
      
    
    </summary>
    
    
      <category term="machine learning" scheme="https://aaronzhou-whu.github.io/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>二叉树相关算法题</title>
    <link href="https://aaronzhou-whu.github.io/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/二叉树相关算法题/</id>
    <published>2018-06-07T05:33:51.000Z</published>
    <updated>2018-09-03T14:12:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>二叉树定义：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Definition <span class="keyword">for</span> a binary tree node.</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> val;</span><br><span class="line">    TreeNode left;</span><br><span class="line">    TreeNode right;</span><br><span class="line">    TreeNode(<span class="keyword">int</span> x) &#123; val = x; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>先序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">        preOrderTraverse(root.left);  </span><br><span class="line">        preOrderTraverse(root.right);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>先序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">    LinkedList&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    TreeNode pNode = root;</span><br><span class="line">    <span class="keyword">while</span> (pNode != <span class="keyword">null</span> || !stack.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">            System.out.print(pNode.val+<span class="string">"  "</span>);</span><br><span class="line">            stack.push(pNode);</span><br><span class="line">            pNode = pNode.left;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            TreeNode node = stack.pop();</span><br><span class="line">            pNode = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>中序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse1</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        inOrderTraverse1(root.left);  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">        inOrderTraverse1(root.right);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>中序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inOrderTraverse2</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    LinkedList&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    TreeNode pNode = root;  </span><br><span class="line">    <span class="keyword">while</span> (pNode != <span class="keyword">null</span> || !stack.isEmpty()) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (pNode != <span class="keyword">null</span>) &#123;  </span><br><span class="line">            stack.push(pNode);  </span><br><span class="line">            pNode = pNode.left;  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">            TreeNode node = stack.pop();  </span><br><span class="line">            System.out.print(node.val+<span class="string">"  "</span>);  </span><br><span class="line">            pNode = node.right;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后序遍历（递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;  </span><br><span class="line">        postOrderTraverse(root.left);  </span><br><span class="line">        postOrderTraverse(root.right);  </span><br><span class="line">        System.out.print(root.val+<span class="string">"  "</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后序遍历（非递归）：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postOrderTraverse</span><span class="params">(TreeNode root)</span> </span>&#123;  </span><br><span class="line">    <span class="comment">// 待续... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二叉树定义：&lt;br&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>python多版本共存下pip安装包问题</title>
    <link href="https://aaronzhou-whu.github.io/python%E5%A4%9A%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98%E4%B8%8Bpip%E5%AE%89%E8%A3%85%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>https://aaronzhou-whu.github.io/python多版本共存下pip安装包问题/</id>
    <published>2018-05-14T06:39:33.000Z</published>
    <updated>2018-05-14T07:04:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>现在一般的机器上都默认带有python2.6或2.7，但是有些项目会用到python3.x，大部分人都是安装多版本的python环境，pip install packagename，import packagename，提示:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ModuleNotFoundError: No module named &apos;packagename&apos;</span><br></pre></td></tr></table></figure></p><p>明明packagename已经安装上了,说明python没有找到packagename.so这个文件，找到这个文件，copy到python的site-packages目录下即可。</p><h3 id="step1-找到pip下载的包所在路径"><a href="#step1-找到pip下载的包所在路径" class="headerlink" title="step1 找到pip下载的包所在路径"></a>step1 找到pip下载的包所在路径</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip -V</span><br><span class="line">pip 10.0.1 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)</span><br></pre></td></tr></table></figure><p>/usr/local/lib/python3.6/site-packages 记为path1</p><h3 id="step2-找到当前python所指向的site-packages"><a href="#step2-找到当前python所指向的site-packages" class="headerlink" title="step2 找到当前python所指向的site-packages"></a>step2 找到当前python所指向的site-packages</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> os</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>os.path.dirname(os.__file__)</span><br><span class="line"><span class="string">'/usr/local/python3/lib/python3.6'</span></span><br></pre></td></tr></table></figure><p>/usr/local/python3/lib/python3.6 记为path2</p><h3 id="step3-复制path1路径下的packagename-xx-so文件到path2"><a href="#step3-复制path1路径下的packagename-xx-so文件到path2" class="headerlink" title="step3 复制path1路径下的packagename-xx.so文件到path2"></a>step3 复制path1路径下的packagename-xx.so文件到path2</h3><p>路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp path1/packagename-xx.so path2</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在一般的机器上都默认带有python2.6或2.7，但是有些项目会用到python3.x，大部分人都是安装多版本的python环境，pip install packagename，import packagename，提示:&lt;br&gt;&lt;figure class=&quot;highl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>多线程编程中的三个核心概念</title>
    <link href="https://aaronzhou-whu.github.io/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B%E4%B8%AD%E7%9A%84%E4%B8%89%E4%B8%AA%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/"/>
    <id>https://aaronzhou-whu.github.io/多线程编程中的三个核心概念/</id>
    <published>2018-04-13T02:43:26.000Z</published>
    <updated>2018-06-20T08:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转发自技术世界，原文链接　<a href="http://www.jasongj.com/java/thread_safe/" target="_blank" rel="noopener">http://www.jasongj.com/java/thread_safe/</a></p></blockquote><p>多线程编程中的三个核心概念<br>原子性<br>这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。</p><p>可见性<br>可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。</p><p>顺序性<br>顺序性指的是，程序执行的顺序按照代码的先后顺序执行。</p><h2 id="Java如何保证原子性"><a href="#Java如何保证原子性" class="headerlink" title="Java如何保证原子性"></a>Java如何保证原子性</h2><p>锁和同步</p><p>常用的保证Java操作原子性的工具是锁和同步方法（或者同步代码块）。使用锁，可以保证同一时间只有一个线程能拿到锁，也就保证了同一时间只有一个线程能执行申请锁和释放锁之间的代码。</p><p>与锁类似的是同步方法或者同步代码块。使用非静态同步方法时，锁住的是当前实例；使用静态同步方法时，锁住的是该类的Class对象；使用静态代码块时，锁住的是synchronized关键字后面括号内的对象。下面是同步代码块示例</p><p>无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。</p><p>CAS（compare and swap）</p><p>基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。AtomicInteger使用方法如下。</p><h2 id="Java如何保证可见性"><a href="#Java如何保证可见性" class="headerlink" title="Java如何保证可见性"></a>Java如何保证可见性</h2><p>Java提供了volatile关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。</p><h2 id="Java如何保证顺序性"><a href="#Java如何保证顺序性" class="headerlink" title="Java如何保证顺序性"></a>Java如何保证顺序性</h2><p>上文讲过编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。</p><p>Java中可通过volatile在一定程序上保证顺序性，另外还可以通过synchronized和锁来保证顺序性。</p><p>synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。</p><p>除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为happens-before原则隐式地保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。</p><h2 id="happens-before原则（先行发生原则）"><a href="#happens-before原则（先行发生原则）" class="headerlink" title="happens-before原则（先行发生原则）"></a>happens-before原则（先行发生原则）</h2><p>传递规则：如果操作1在操作2前面，而操作2在操作3前面，则操作1肯定会在操作3前发生。该规则说明了happens-before原则具有传递性<br>锁定规则：一个unlock操作肯定会在后面对同一个锁的lock操作前发生。这个很好理解，锁只有被释放了才会被再次获取<br>volatile变量规则：对一个被volatile修饰的写操作先发生于后面对该变量的读操作<br>程序次序规则：一个线程内，按照代码顺序执行<br>线程启动规则：Thread对象的start()方法先发生于此线程的其它动作<br>线程终结原则：线程的终止检测后发生于线程中其它的所有操作<br>线程中断规则： 对线程interrupt()方法的调用先发生于对该中断异常的获取<br>对象终结规则：一个对象构造先于它的finalize发生<br>volatile适用场景<br>volatile适用于不需要保证原子性，但却需要保证可见性的场景。</p><h2 id="线程安全十万个为什么"><a href="#线程安全十万个为什么" class="headerlink" title="线程安全十万个为什么"></a>线程安全十万个为什么</h2><p>问：平时项目中使用锁和synchronized比较多，而很少使用volatile，难道就没有保证可见性？<br>答：锁和synchronized即可以保证原子性，也可以保证可见性。都是通过保证同一时间只有一个线程执行目标代码段来实现的。</p><p>问：锁和synchronized为何能保证可见性？<br>答：根据JDK 7的Java doc中对concurrent包的说明，一个线程的写结果保证对另外线程的读操作可见，只要该写操作可以由happen-before原则推断出在读操作之前发生。</p><p>The results of a write by one thread are guaranteed to be visible to a read by another thread only if the write operation happens-before the read operation. The synchronized and volatile constructs, as well as the Thread.start() and Thread.join() methods, can form happens-before relationships.</p><p>问：既然锁和synchronized即可保证原子性也可保证可见性，为何还需要volatile？<br>答：synchronized和锁需要通过操作系统来仲裁谁获得锁，开销比较高，而volatile开销小很多。因此在只需要保证可见性的条件下，使用volatile的性能要比使用锁和synchronized高得多。</p><p>问：既然锁和synchronized可以保证原子性，为什么还需要AtomicInteger这种的类来保证原子操作？<br>答：锁和synchronized需要通过操作系统来仲裁谁获得锁，开销比较高，而AtomicInteger是通过CPU级的CAS操作来保证原子性，开销比较小。所以使用AtomicInteger的目的还是为了提高性能。</p><p>问：还有没有别的办法保证线程安全<br>答：有。尽可能避免引起非线程安全的条件——共享变量。如果能从设计上避免共享变量的使用，即可避免非线程安全的发生，也就无须通过锁或者synchronized以及volatile解决原子性、可见性和顺序性的问题。</p><p>问：synchronized即可修饰非静态方式，也可修饰静态方法，还可修饰代码块，有何区别<br>答：synchronized修饰非静态同步方法时，锁住的是当前实例；synchronized修饰静态同步方法时，锁住的是该类的Class对象；synchronized修饰静态代码块时，锁住的是synchronized关键字后面括号内的对象。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本文转发自技术世界，原文链接　&lt;a href=&quot;http://www.jasongj.com/java/thread_safe/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.jasongj.com/java
      
    
    </summary>
    
    
      <category term="多线程" scheme="https://aaronzhou-whu.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>常见的几种概率名词</title>
    <link href="https://aaronzhou-whu.github.io/%E5%B8%B8%E8%A7%81%E7%9A%84%E5%87%A0%E7%A7%8D%E6%A6%82%E7%8E%87%E5%90%8D%E8%AF%8D/"/>
    <id>https://aaronzhou-whu.github.io/常见的几种概率名词/</id>
    <published>2018-04-02T16:02:23.000Z</published>
    <updated>2018-04-02T16:05:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然<br>总是容易搞混，这里总结一下常规的叫法：</p><p><strong>先验概率：</strong><br>事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单独事件概率，如P(x),P(y)。</p><p><strong>后验概率：</strong><br>事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。</p><p><strong>条件概率：</strong><br>一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件下x发生的概率。</p><p><strong>贝叶斯公式：</strong><br>P(y|x) = ( P(x|y) * P(y) ) / P(x)</p><p>这里：<br>P(y|x) 是后验概率，一般是我们求解的目标。</p><p>P(x|y) 是条件概率，又叫似然概率，一般是通过历史数据统计得到。一般不把它叫做先验概率，但从定义上也符合先验定义。</p><p>P(y) 是先验概率，一般都是人主观给出的。贝叶斯中的先验概率一般特指它。</p><p>P(x) 其实也是先验概率，只是在贝叶斯的很多应用中不重要（因为只要最大后验不求绝对值），需要时往往用全概率公式计算得到。</p><p>实例：假设y是文章种类，是一个枚举值；x是向量，表示文章中各个单词的出现次数。</p><p>在拥有训练集的情况下，显然除了后验概率P(y|x)中的x来自一篇新文章无法得到，p(x),p(y),p(x|y)都是可以在抽样集合上统计出的。</p><p><strong>最大似然理论：</strong></p><p>认为P(x|y)最大的类别y，就是当前文档所属类别。即Max P(x|y) = Max p(x1|y)<em>p(x2|y)</em>…p(xn|y), for all y</p><p><strong>贝叶斯理论：</strong></p><p>认为需要增加先验概率p(y)，因为有可能某个y是很稀有的类别几千年才看见一次，即使P(x|y)很高，也很可能不是它。</p><p>所以y = Max P(x|y) * P(y), 其中p(y)一般是数据集里统计出来的。</p><p>从上例来讲，贝叶斯理论显然更合理一些；但实际中很多先验概率是拍脑袋得出的（不准），有些甚至是为了方便求解方便生造出来的（硬凑），那有先验又有什么好处呢？一般攻击贝叶斯都在于这一点</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;先验概率，后验概率，似然概率，条件概率，贝叶斯，最大似然&lt;br&gt;总是容易搞混，这里总结一下常规的叫法：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;先验概率：&lt;/strong&gt;&lt;br&gt;事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>一致性哈希</title>
    <link href="https://aaronzhou-whu.github.io/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/"/>
    <id>https://aaronzhou-whu.github.io/一致性哈希/</id>
    <published>2018-03-28T05:35:08.000Z</published>
    <updated>2018-06-20T08:00:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>均衡性：哈希的结果能够尽可能分布到所有的缓存中去。</p><p>单调性：当缓冲区大小变化时一致性哈希尽量保护已分配的内容不会被重新映射到新缓冲区。</p><p>分散性：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。</p><p>负载：另一个维度的分散性问题，对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。</p><p>首先，求出每个服务器的hash值，将其配置到一个 0~2^n 的圆环上（n通常取32）；<br>其次，用同样的方法求出待存储对象的主键 hash值，也将其配置到这个圆环上；<br>再次，从数据映射到的位置开始顺时针查找，将数据分布到找到的第一个服务器节点上。一致性hash的优点在于加入和删除节点时只会影响到在哈希环中相邻的节点，而对其他节点没有影响。</p><p>平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。hash 算法并不是保证绝对的平衡，<br>为了解决这种情况， consistent hashing 引入了“虚拟节点”的概念，它可以如下定义：<br>“虚拟节点”（ virtual node ）是实际节点在 hash 空间的复制品（ replica ），一实际个节点对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以 hash 值排列。</p><p>ps:摘选自网上很多blog，谢谢他们！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;均衡性：哈希的结果能够尽可能分布到所有的缓存中去。&lt;/p&gt;
&lt;p&gt;单调性：当缓冲区大小变化时一致性哈希尽量保护已分配的内容不会被重新映射到新缓冲区。&lt;/p&gt;
&lt;p&gt;分散性：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://aaronzhou-whu.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>流式计算框架--Storm</title>
    <link href="https://aaronzhou-whu.github.io/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%A1%86%E6%9E%B6-Storm/"/>
    <id>https://aaronzhou-whu.github.io/流式计算框架-Storm/</id>
    <published>2018-03-16T07:50:46.000Z</published>
    <updated>2018-03-16T08:23:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>Storm是一个分布式的，可靠的，容错的数据流处理系统。它是一个流式计算框架，时延低，无状态的，它通过Apache ZooKeeper管理分布式环境和集群状态，适合实时计算。</p><p>Apache Storm的组件：<br>| 组件 | 描述 |<br>| :-: |  |<br>| Tuple     | 它是有序元素的列表，一组逗号分隔的值，Tuple支持所有数据类型，并传递到Storm集群 |<br>| Stream        |   流是元组的无序序列  |<br>| Spouts        |   Storm从原始数据源（如 Kafka队列，Kestrel队列等）接受输入数据  |<br>| Bolts        |Bolts是逻辑处理单元，接收spout的输入，并产生新的数据流   |</p><p>Storm集群概念：<br>| 组件 | 描述 |<br>| :- | :- |<br>|Nimbus（主节点）|    Nimbus是Storm集群的主节点。集群中的所有其他节点称为工作节点。主节点负责在所有工作节点之间分发数据，向工作节点分配任务和监视故障。|<br>|Supervisor（工作节点）|    遵循指令的节点被称为Supervisors。Supervisor有多个工作进程，它管理工作进程以完成由nimbus分配的任务。|<br>|Worker process（工作进程）|    工作进程将执行与特定拓扑相关的任务。工作进程不会自己运行任务，而是创建执行器并要求他们执行特定的任务。工作进程将有多个执行器。|<br>|Executor（执行者）|执行器只是工作进程产生的单个线程。执行器运行一个或多个任务，但仅用于特定的spout或bolt。|<br>|Task（任务）|任务执行实际的数据处理。所以，它是一个spout或bolt。|<br>|ZooKeeper framework（ZooKeeper框架）|Apache的ZooKeeper的是使用群集（节点组）自己和维护具有强大的同步技术共享数据之间进行协调的服务。Nimbus是无状态的，所以它依赖于ZooKeeper来监视工作节点的状态。ZooKeeper的帮助supervisor与nimbus交互。它负责维持nimbus，supervisor的状态。|</p><p>Apache Storm的工作流程 −</p><ol><li>nimbus接收到提交的“Storm拓扑”，并将任务分配给所有的supervisors</li><li>在特定的时间间隔，所有supervisor将向nimbus发送心跳以通知它们仍然运行着。</li><li>当nimbus检测不到supervisor的心跳时，会将任务分配给另一个supervisor。</li><li>当nimbus本身终止时，supervisor将在没有任何问题的情况下对已经分配的任务进行工作。</li><li>一旦所有的任务都完成后，supervisor将等待新的任务进去；同时，nimbus将由服务监控工具自动重新启动。</li><li>由于网络管理程序和supervisor都可以自动重新启动，并且两者将像以前一样继续，因此Storm保证至少处理所有任务一次。</li><li>一旦处理了所有拓扑，则网络管理器等待新的拓扑到达，并且类似地，管理器等待新的任务。</li></ol><p>默认情况下，Storm集群中有两种模式：</p><blockquote><ul><li>本地模式 -此模式用于开发，测试和调试，因为它是查看所有拓扑组件协同工作的最简单方法。在这种模式下，我们可以调整参数，使我们能够看到我们的拓扑如何在不同的Storm配置环境中运行。在本地模式下，storm拓扑在本地机器上在单个JVM中运行。</li><li>生产模式 -在这种模式下，我们将拓扑提交到工作Storm集群，该集群由许多进程组成，通常运行在不同的机器上。如在storm的工作流中所讨论的，工作集群将无限地运行，直到它被关闭。</li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Storm是一个分布式的，可靠的，容错的数据流处理系统。它是一个流式计算框架，时延低，无状态的，它通过Apache ZooKeeper管理分布式环境和集群状态，适合实时计算。&lt;/p&gt;
&lt;p&gt;Apache Storm的组件：&lt;br&gt;| 组件 | 描述 |&lt;br&gt;| :-: |
      
    
    </summary>
    
    
  </entry>
  
</feed>
